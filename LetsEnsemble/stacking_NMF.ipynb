{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92d257cd-824a-4921-8b21-c14bada43824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/sarmat/lgbm-stacking-example/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1cc2c9a-80ee-4932-b759-7f49c34b9ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd\n",
    "import random\n",
    "from scipy.sparse.linalg import svds\n",
    "import os\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from dataset import custom_train_test_split, make_dataset\n",
    "\n",
    "from sklearn.metrics import RocCurveDisplay, accuracy_score, roc_auc_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "\n",
    "\n",
    "def get_metric(targets, preds):\n",
    "    auc = roc_auc_score(targets, preds)\n",
    "    acc = accuracy_score(targets, np.where(preds >= 0.5, 1, 0))\n",
    "    precsion = precision_score(targets, np.where(preds >= 0.5, 1, 0))\n",
    "    recall = recall_score(targets, np.where(preds >= 0.5, 1, 0))\n",
    "    F1_score = f1_score(targets, np.where(preds >= 0.5, 1, 0))\n",
    "\n",
    "    print('auc :',auc)\n",
    "    print('acc :',acc)\n",
    "    print('precision :',precsion)\n",
    "    print('recall :',recall)\n",
    "\n",
    "def test_to_csv(preds, name:str):\n",
    "    \n",
    "    result = []\n",
    "    for n,i in enumerate(preds):\n",
    "        row = {}    \n",
    "        row['id'] = n\n",
    "        row['prediction'] = i\n",
    "        result.append(row)\n",
    "    pd.DataFrame(result).to_csv(name+'.csv', index=None)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e3621d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "NMF01 \n",
    "auc : 0.7953\n",
    "acc : 0.7684\n",
    "precision : 0.7832\n",
    "recall : 0.8940\n",
    "\n",
    "auc : 0.7972041283367117\n",
    "acc : 0.7695351098548522\n",
    "precision : 0.7839268704708476\n",
    "recall : 0.8949562918681847\n",
    "AUC NMF02:None \n",
    "auc : 0.7998546055565555\n",
    "acc : 0.7694918056665498\n",
    "precision : 0.7834012776330167\n",
    "recall : 0.8959235783592178\n",
    "AUC NMF03:None \n",
    "auc : 0.8023755707592811\n",
    "acc : 0.7718459788124417\n",
    "precision : 0.7858219257479477\n",
    "recall : 0.8960197062092583\n",
    "AUC NMF04:None \n",
    "auc : 0.804514090366049\n",
    "acc : 0.7735427156450159\n",
    "precision : 0.787716934780886\n",
    "recall : 0.8958094265372946\n",
    "AUC NMF05:None \n",
    "auc : 0.8066111525597577\n",
    "acc : 0.7742040887027246\n",
    "precision : 0.7885876035025529\n",
    "recall : 0.8954729790621526\n",
    "AUC NMF06:None \n",
    "auc : 0.8082522468764606\n",
    "acc : 0.7749717538589936\n",
    "precision : 0.7896567078730307\n",
    "recall : 0.8949743158400673\n",
    "AUC NMF07:None \n",
    "auc : 0.8099958597197554\n",
    "acc : 0.776227575319762\n",
    "precision : 0.7909170537491705\n",
    "recall : 0.8951245156057557\n",
    "AUC NMF08:None \n",
    "auc : 0.8118606391044008\n",
    "acc : 0.7777747158654735\n",
    "precision : 0.7926297194909122\n",
    "recall : 0.8950103637838325\n",
    "AUC NMF09:None \n",
    "auc : 0.8139937635119844\n",
    "acc : 0.7786368628871296\n",
    "precision : 0.7937734893514939\n",
    "recall : 0.8945898044399051\n",
    "AUC NMF10:None \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbfda087",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('/opt/ml/input/data/all.csv')\n",
    "test_data  = pd.read_csv('/opt/ml/input/data/test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddcb5a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop_duplicates(subset = [\"userID\", \"assessmentItemID\"], keep = \"last\", inplace = True)\n",
    "train_data.drop(['Timestamp','testId','KnowledgeTag'], axis=1, inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b5f7b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_train = train_data.pivot_table('answerCode', index='userID', columns='assessmentItemID')\n",
    "matrix_train.fillna(0.5, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c459f8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id2idx = {v:i for i,v in enumerate(matrix_train.index)}\n",
    "user_idx2id = {i:v for i,v in enumerate(matrix_train.index)}\n",
    "\n",
    "item_id2idx = {v:i for i,v in enumerate(matrix_train.columns)}\n",
    "item_idx2id = {i:v for i,v in enumerate(matrix_train.columns)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2009cb8-ba5a-4af8-a999-7b72297ae915",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:289: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1637: ConvergenceWarning: Maximum number of iterations 1000 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:289: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1637: ConvergenceWarning: Maximum number of iterations 1000 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:289: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1637: ConvergenceWarning: Maximum number of iterations 1000 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:289: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1637: ConvergenceWarning: Maximum number of iterations 1000 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:289: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1637: ConvergenceWarning: Maximum number of iterations 1000 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:289: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1637: ConvergenceWarning: Maximum number of iterations 1000 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:289: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1637: ConvergenceWarning: Maximum number of iterations 1000 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:289: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1637: ConvergenceWarning: Maximum number of iterations 1000 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:289: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1637: ConvergenceWarning: Maximum number of iterations 1000 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:289: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1637: ConvergenceWarning: Maximum number of iterations 1000 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NMF(max_iter=1000, n_components=38)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf01 = NMF(n_components=20, max_iter=1000)\n",
    "nmf02 = NMF(n_components=22, max_iter=1000)\n",
    "nmf03 = NMF(n_components=24, max_iter=1000)\n",
    "nmf04 = NMF(n_components=26, max_iter=1000)\n",
    "nmf05 = NMF(n_components=28, max_iter=1000)\n",
    "nmf06 = NMF(n_components=30, max_iter=1000)\n",
    "nmf07 = NMF(n_components=32, max_iter=1000)\n",
    "nmf08 = NMF(n_components=34, max_iter=1000)\n",
    "nmf09 = NMF(n_components=36, max_iter=1000)\n",
    "nmf10 = NMF(n_components=38, max_iter=1000)\n",
    "\n",
    "nmf01.fit(matrix_train)\n",
    "nmf02.fit(matrix_train)\n",
    "nmf03.fit(matrix_train)\n",
    "nmf04.fit(matrix_train)\n",
    "nmf05.fit(matrix_train)\n",
    "nmf06.fit(matrix_train)\n",
    "nmf07.fit(matrix_train)\n",
    "nmf08.fit(matrix_train)\n",
    "nmf09.fit(matrix_train)\n",
    "nmf10.fit(matrix_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "713964ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(matrix, userid, itemid, user_id2idx, item_id2idx, model):\n",
    "\n",
    "    X_pred = model.inverse_transform(model.transform(matrix))\n",
    "\n",
    "    ret = [X_pred[user_id2idx[u], item_id2idx[i]] for u,i in zip(userid, itemid)]\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c404f1b8-04c6-49bf-843b-3f3485fd513a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but NMF was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but NMF was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but NMF was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but NMF was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but NMF was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but NMF was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but NMF was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but NMF was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but NMF was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but NMF was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but NMF was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but NMF was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but NMF was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but NMF was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but NMF was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but NMF was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but NMF was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but NMF was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but NMF was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but NMF was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc : 0.7953082801102949\n",
      "acc : 0.7684643153804667\n",
      "precision : 0.7832797292246793\n",
      "recall : 0.8940010213584066\n",
      "AUC NMF01:None \n",
      "auc : 0.7972041283367117\n",
      "acc : 0.7695351098548522\n",
      "precision : 0.7839268704708476\n",
      "recall : 0.8949562918681847\n",
      "AUC NMF02:None \n",
      "auc : 0.7998546055565555\n",
      "acc : 0.7694918056665498\n",
      "precision : 0.7834012776330167\n",
      "recall : 0.8959235783592178\n",
      "AUC NMF03:None \n",
      "auc : 0.8023755707592811\n",
      "acc : 0.7718459788124417\n",
      "precision : 0.7858219257479477\n",
      "recall : 0.8960197062092583\n",
      "AUC NMF04:None \n",
      "auc : 0.804514090366049\n",
      "acc : 0.7735427156450159\n",
      "precision : 0.787716934780886\n",
      "recall : 0.8958094265372946\n",
      "AUC NMF05:None \n",
      "auc : 0.8066111525597577\n",
      "acc : 0.7742040887027246\n",
      "precision : 0.7885876035025529\n",
      "recall : 0.8954729790621526\n",
      "AUC NMF06:None \n",
      "auc : 0.8082522468764606\n",
      "acc : 0.7749717538589936\n",
      "precision : 0.7896567078730307\n",
      "recall : 0.8949743158400673\n",
      "AUC NMF07:None \n",
      "auc : 0.8099958597197554\n",
      "acc : 0.776227575319762\n",
      "precision : 0.7909170537491705\n",
      "recall : 0.8951245156057557\n",
      "AUC NMF08:None \n",
      "auc : 0.8118606391044008\n",
      "acc : 0.7777747158654735\n",
      "precision : 0.7926297194909122\n",
      "recall : 0.8950103637838325\n",
      "AUC NMF09:None \n",
      "auc : 0.8139937635119844\n",
      "acc : 0.7786368628871296\n",
      "precision : 0.7937734893514939\n",
      "recall : 0.8945898044399051\n",
      "AUC NMF10:None \n"
     ]
    }
   ],
   "source": [
    "valid_user  = pd.read_csv('/opt/ml/input/data/cv_valid_data.csv').userID.unique()\n",
    "all_train = pd.read_csv('/opt/ml/input/data/all.csv')\n",
    "valid_data = all_train[all_train.userID.isin(valid_user)]\n",
    "userid = sorted(list(set([u for u in valid_data.userID])))\n",
    "user_id2idx_valid = {v:i for i,v in enumerate(userid)}\n",
    "\n",
    "matrix_valid = 0.5*np.ones((len(userid), len(item_id2idx)))\n",
    "for user,item,a in zip(valid_data.userID, valid_data.assessmentItemID, valid_data.answerCode):\n",
    "    user,item = user_id2idx_valid[user],item_id2idx[item]\n",
    "    matrix_valid[user,item] = a\n",
    "\n",
    "\n",
    "\n",
    "valid_predict01 = predict(matrix_valid, valid_data.userID, valid_data.assessmentItemID, user_id2idx_valid, item_id2idx, nmf01 )\n",
    "valid_predict02 = predict(matrix_valid, valid_data.userID, valid_data.assessmentItemID, user_id2idx_valid, item_id2idx, nmf02 )\n",
    "valid_predict03 = predict(matrix_valid, valid_data.userID, valid_data.assessmentItemID, user_id2idx_valid, item_id2idx, nmf03 )\n",
    "valid_predict04 = predict(matrix_valid, valid_data.userID, valid_data.assessmentItemID, user_id2idx_valid, item_id2idx, nmf04 )\n",
    "valid_predict05 = predict(matrix_valid, valid_data.userID, valid_data.assessmentItemID, user_id2idx_valid, item_id2idx, nmf05 )\n",
    "valid_predict06 = predict(matrix_valid, valid_data.userID, valid_data.assessmentItemID, user_id2idx_valid, item_id2idx, nmf06 )\n",
    "valid_predict07 = predict(matrix_valid, valid_data.userID, valid_data.assessmentItemID, user_id2idx_valid, item_id2idx, nmf07 )\n",
    "valid_predict08 = predict(matrix_valid, valid_data.userID, valid_data.assessmentItemID, user_id2idx_valid, item_id2idx, nmf08 )\n",
    "valid_predict09 = predict(matrix_valid, valid_data.userID, valid_data.assessmentItemID, user_id2idx_valid, item_id2idx, nmf09 )\n",
    "valid_predict10 = predict(matrix_valid, valid_data.userID, valid_data.assessmentItemID, user_id2idx_valid, item_id2idx, nmf10 )\n",
    "\n",
    "# item_id2idx는 train에서 사용한 것을 다시 사용한다.\n",
    "test_data  = pd.read_csv('/opt/ml/input/data/test_data.csv')\n",
    "\n",
    "userid = sorted(list(set([u for u in test_data.userID])))\n",
    "user_id2idx_test = {v:i for i,v in enumerate(userid)}\n",
    "\n",
    "matrix_test = 0.5*np.ones((len(userid), len(item_id2idx)))\n",
    "for user,item,a in zip(test_data.userID, test_data.assessmentItemID, test_data.answerCode):\n",
    "    user,item = user_id2idx_test[user],item_id2idx[item]\n",
    "    if a<0:a=0.5\n",
    "    matrix_test[user,item] = a\n",
    "\n",
    "test_data = test_data[test_data.answerCode==-1]\n",
    "\n",
    "test_predict01 = predict(matrix_test, test_data.userID, test_data.assessmentItemID, user_id2idx_test, item_id2idx, nmf01 )\n",
    "test_predict02 = predict(matrix_test, test_data.userID, test_data.assessmentItemID, user_id2idx_test, item_id2idx, nmf02 )\n",
    "test_predict03 = predict(matrix_test, test_data.userID, test_data.assessmentItemID, user_id2idx_test, item_id2idx, nmf03 )\n",
    "test_predict04 = predict(matrix_test, test_data.userID, test_data.assessmentItemID, user_id2idx_test, item_id2idx, nmf04 )\n",
    "test_predict05 = predict(matrix_test, test_data.userID, test_data.assessmentItemID, user_id2idx_test, item_id2idx, nmf05 )\n",
    "test_predict06 = predict(matrix_test, test_data.userID, test_data.assessmentItemID, user_id2idx_test, item_id2idx, nmf06 )\n",
    "test_predict07 = predict(matrix_test, test_data.userID, test_data.assessmentItemID, user_id2idx_test, item_id2idx, nmf07 )\n",
    "test_predict08 = predict(matrix_test, test_data.userID, test_data.assessmentItemID, user_id2idx_test, item_id2idx, nmf08 )\n",
    "test_predict09 = predict(matrix_test, test_data.userID, test_data.assessmentItemID, user_id2idx_test, item_id2idx, nmf09 )\n",
    "test_predict10 = predict(matrix_test, test_data.userID, test_data.assessmentItemID, user_id2idx_test, item_id2idx, nmf10 )\n",
    "\n",
    "# print('Fold no: {}'.format(fold_))\n",
    "print(\"AUC NMF01:{} \".format(get_metric(valid_data.answerCode.to_numpy(), np.array(valid_predict01))))\n",
    "print(\"AUC NMF02:{} \".format(get_metric(valid_data.answerCode.to_numpy(), np.array(valid_predict02))))\n",
    "print(\"AUC NMF03:{} \".format(get_metric(valid_data.answerCode.to_numpy(), np.array(valid_predict03))))\n",
    "print(\"AUC NMF04:{} \".format(get_metric(valid_data.answerCode.to_numpy(), np.array(valid_predict04))))\n",
    "print(\"AUC NMF05:{} \".format(get_metric(valid_data.answerCode.to_numpy(), np.array(valid_predict05)))) \n",
    "print(\"AUC NMF06:{} \".format(get_metric(valid_data.answerCode.to_numpy(), np.array(valid_predict06)))) \n",
    "print(\"AUC NMF07:{} \".format(get_metric(valid_data.answerCode.to_numpy(), np.array(valid_predict07)))) \n",
    "print(\"AUC NMF08:{} \".format(get_metric(valid_data.answerCode.to_numpy(), np.array(valid_predict08)))) \n",
    "print(\"AUC NMF09:{} \".format(get_metric(valid_data.answerCode.to_numpy(), np.array(valid_predict09)))) \n",
    "print(\"AUC NMF10:{} \".format(get_metric(valid_data.answerCode.to_numpy(), np.array(valid_predict10))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3fa643ea-8fdc-40ab-969b-a35e6de280a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = '/opt/ml/level2-dkt-level2-recsys-08/LetsEnsemble/test4feature'\n",
    "valid_path = '/opt/ml/level2-dkt-level2-recsys-08/LetsEnsemble/valid4feature'\n",
    "\n",
    "test_to_csv( valid_predict01, os.path.join(valid_path, 'NMF_valid01') )\n",
    "test_to_csv( valid_predict02, os.path.join(valid_path, 'NMF_valid02') )\n",
    "test_to_csv( valid_predict03, os.path.join(valid_path, 'NMF_valid03') )\n",
    "test_to_csv( valid_predict04, os.path.join(valid_path, 'NMF_valid04') )\n",
    "test_to_csv( valid_predict05, os.path.join(valid_path, 'NMF_valid05') )\n",
    "test_to_csv( valid_predict06, os.path.join(valid_path, 'NMF_valid06') )\n",
    "test_to_csv( valid_predict07, os.path.join(valid_path, 'NMF_valid07') )\n",
    "test_to_csv( valid_predict08, os.path.join(valid_path, 'NMF_valid08') )\n",
    "test_to_csv( valid_predict09, os.path.join(valid_path, 'NMF_valid09') )\n",
    "test_to_csv( valid_predict10, os.path.join(valid_path, 'NMF_valid10') )\n",
    "\n",
    "test_to_csv( test_predict01, os.path.join(test_path, 'NMF_test01') )\n",
    "test_to_csv( test_predict02, os.path.join(test_path, 'NMF_test02') )\n",
    "test_to_csv( test_predict03, os.path.join(test_path, 'NMF_test03') )\n",
    "test_to_csv( test_predict04, os.path.join(test_path, 'NMF_test04') )\n",
    "test_to_csv( test_predict05, os.path.join(test_path, 'NMF_test05') )\n",
    "test_to_csv( test_predict06, os.path.join(test_path, 'NMF_test06') )\n",
    "test_to_csv( test_predict07, os.path.join(test_path, 'NMF_test07') )\n",
    "test_to_csv( test_predict08, os.path.join(test_path, 'NMF_test08') )\n",
    "test_to_csv( test_predict09, os.path.join(test_path, 'NMF_test09') )\n",
    "test_to_csv( test_predict10, os.path.join(test_path, 'NMF_test10') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a496d655",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_valid = np.array([\n",
    "                        valid_predict01,\n",
    "                        valid_predict02,\n",
    "                        valid_predict03,\n",
    "                        valid_predict04,\n",
    "                        valid_predict05,\n",
    "                        valid_predict06,\n",
    "                        valid_predict07,\n",
    "                        valid_predict08,\n",
    "                        valid_predict09,\n",
    "                        valid_predict10,\n",
    "                        valid_predict11,\n",
    "                        valid_predict12,\n",
    "                        valid_predict13,\n",
    "                        valid_predict14,\n",
    "                        valid_predict15,\n",
    "                        valid_predict16,\n",
    "                        valid_predict17,\n",
    "                        valid_predict18,]).T\n",
    "\n",
    "new_test = np.array([\n",
    "                        test_predict01,\n",
    "                        test_predict02,\n",
    "                        test_predict03,\n",
    "                        test_predict04,\n",
    "                        test_predict05,\n",
    "                        test_predict06,\n",
    "                        test_predict07,\n",
    "                        test_predict08,\n",
    "                        test_predict09,\n",
    "                        test_predict10,\n",
    "                        test_predict11,\n",
    "                        test_predict12,\n",
    "                        test_predict13,\n",
    "                        test_predict14,\n",
    "                        test_predict15,\n",
    "                        test_predict16,\n",
    "                        test_predict17,\n",
    "                        test_predict18,]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9e5fd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = pd.read_csv('/opt/ml/input/data/cv_valid_data.csv')\n",
    "tail_idx = val.index[val.answerCode==-1].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "106ded69",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid = valid_data.answerCode.to_numpy()\n",
    "\n",
    "valid_tail = [new_valid[i] for i in range(len(new_valid)) if i in tail_idx]\n",
    "y_tail = [y_valid[i] for i in range(len(y_valid)) if i in tail_idx]\n",
    "\n",
    "new_valid = [new_valid[i] for i in range(len(new_valid)) if not i in tail_idx]\n",
    "y_new_valid = [y_valid[i] for i in range(len(y_valid)) if not i in tail_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fae54566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38d30d8271f244b2a537ffddc4e1e85e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f04c04f3a00>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "train_pool = Pool(new_valid, y_new_valid)\n",
    "# eval_pool = Pool(valid_tail , y_tail)\n",
    "eval_pool = Pool(valid_tail, y_tail)\n",
    "\n",
    "Final_cat = CatBoostClassifier(\n",
    "            iterations = 500,\n",
    "            random_seed = 42,\n",
    "            learning_rate = 0.01,\n",
    "            loss_function = 'Logloss', \n",
    "            custom_metric = ['Logloss','AUC'],\n",
    "            early_stopping_rounds = 30,\n",
    "            use_best_model =  True,\n",
    "            task_type = \"GPU\",\n",
    "            bagging_temperature = 1,\n",
    "            verbose = False)\n",
    "\n",
    "Final_cat.fit(train_pool, eval_set=eval_pool, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d8210eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc : 0.9045335626734506\n",
      "acc : 0.8198924731182796\n",
      "precision : 0.8145161290322581\n",
      "recall : 0.8233695652173914\n"
     ]
    }
   ],
   "source": [
    "preds = Final_cat.predict(new_test , prediction_type='Probability')[:,1]\n",
    "val_preds = Final_cat.predict(valid_tail , prediction_type='Probability')[:,1]\n",
    "\n",
    "get_metric(y_tail, val_preds)\n",
    "\n",
    "from datetime import date, datetime, timezone, timedelta\n",
    "\n",
    "KST = timezone(timedelta(hours=9))\n",
    "time_record = datetime.now(KST)\n",
    "_day = str(time_record)[:10]\n",
    "_time = str(time_record.time())[:8]\n",
    "now_time = _day+'_'+_time\n",
    "\n",
    "test_to_csv(new_test.mean(axis=1),f'Stacking_NMF_{now_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3c913a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_to_csv( new_test[:,0], 'NMF_38')\n",
    "test_to_csv( new_test[:,1], 'NMF_40')\n",
    "test_to_csv( new_test[:,2], 'NMF_42')\n",
    "test_to_csv( new_test[:,3], 'NMF_44')\n",
    "test_to_csv( new_test[:,4], 'NMF_46')\n",
    "test_to_csv( new_test[:,5], 'NMF_48')\n",
    "test_to_csv( new_test[:,6], 'NMF_50')\n",
    "test_to_csv( new_test[:,7], 'NMF_52')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ae3a7e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "744"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_test[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e2fe59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
