{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d257cd-824a-4921-8b21-c14bada43824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/sarmat/lgbm-stacking-example/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1cc2c9a-80ee-4932-b759-7f49c34b9ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd\n",
    "import random\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from dataset import custom_train_test_split, make_dataset\n",
    "\n",
    "from sklearn.metrics import RocCurveDisplay, accuracy_score, roc_auc_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "\n",
    "\n",
    "def get_metric(targets, preds):\n",
    "    auc = roc_auc_score(targets, preds)\n",
    "    acc = accuracy_score(targets, np.where(preds >= 0.5, 1, 0))\n",
    "    precsion = precision_score(targets, np.where(preds >= 0.5, 1, 0))\n",
    "    recall = recall_score(targets, np.where(preds >= 0.5, 1, 0))\n",
    "    F1_score = f1_score(targets, np.where(preds >= 0.5, 1, 0))\n",
    "\n",
    "    print('auc :',auc)\n",
    "    print('acc :',acc)\n",
    "    print('precision :',precsion)\n",
    "    print('recall :',recall)\n",
    "\n",
    "def test_to_csv(preds, name:str):\n",
    "    \n",
    "    result = []\n",
    "    for n,i in enumerate(preds):\n",
    "        row = {}    \n",
    "        row['id'] = n\n",
    "        row['prediction'] = i\n",
    "        result.append(row)\n",
    "    pd.DataFrame(result).to_csv(f'output/{name}.csv', index=None)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "869464d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cate_cols = [\n",
    "            # 'assessmentItemID',\n",
    "            # 'testId',\n",
    "            # 'KnowledgeTag',\n",
    "            'hour',\n",
    "            'dow',\n",
    "            'i_head',\n",
    "            'i_mid',\n",
    "            'i_tail',\n",
    "]\n",
    "cont_cols = [                        \n",
    "            'user_correct_answer',\n",
    "            'user_total_answer',\n",
    "            'user_acc',            \n",
    "            't_elapsed',            \n",
    "            'cum_correct',\n",
    "            'last_problem',\n",
    "            'head_term',\n",
    "            # 'left_asymptote',\n",
    "            'elo_prob',\n",
    "            'pkt',\n",
    "            'u_head_mean',\n",
    "            'u_head_count',\n",
    "            'u_head_std',\n",
    "            'u_head_elapsed',\n",
    "            'i_mid_elapsed',\n",
    "            'i_mid_mean',\n",
    "            'i_mid_std',\n",
    "            'i_mid_sum',\n",
    "            'i_mid_count',\n",
    "            'i_mid_tag_count',\n",
    "            'assessment_mean',\n",
    "            'assessment_sum',\n",
    "            # 'assessment_std',\n",
    "            'tag_mean',\n",
    "            'tag_sum',\n",
    "            # 'tag_std',\n",
    "            'tail_mean',\n",
    "            'tail_sum',\n",
    "            # 'tail_std',\n",
    "            'hour_mean',\n",
    "            'hour_sum',\n",
    "            # 'hour_std',\n",
    "            'dow_mean',\n",
    "            'dow_sum',\n",
    "            # 'dow_std',\n",
    "            'tag_elapsed',\n",
    "            'tag_elapsed_o',\n",
    "            'tag_elapsed_x',\n",
    "            'assessment_elapsed',\n",
    "            'assessment_elapsed_o',\n",
    "            'assessment_elapsed_x',\n",
    "            'tail_elapsed',\n",
    "            'tail_elapsed_o',\n",
    "            'tail_elapsed_x'\n",
    "            ]\n",
    "\n",
    "FEATS = cate_cols + cont_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbfda087",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('/opt/ml/level2-dkt-level2-recsys-08/data_pkl/all.pkl')\n",
    "label = data.answerCode.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebc46bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model01 = LogisticRegression(max_iter=500, C= 1)\n",
    "model02 = LogisticRegression(max_iter=500, C= 2)\n",
    "model03 = LogisticRegression(max_iter=500, C= 3)\n",
    "model04 = LogisticRegression(max_iter=500, C= 4)\n",
    "model05 = LogisticRegression(max_iter=500, C= 5)\n",
    "model06 = LogisticRegression(max_iter=500, C= 6)\n",
    "model07 = LogisticRegression(max_iter=500, C= 7)\n",
    "model08 = LogisticRegression(max_iter=500, C= 8)\n",
    "model09 = LogisticRegression(max_iter=500, C= 9)\n",
    "model10 = LogisticRegression(max_iter=500, C= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fe66476",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_user = pd.read_csv('/opt/ml/input/data/cv_valid_data.csv').userID.unique()\n",
    "X_train = data[data.userID.isin(valid_user)==False]\n",
    "y_train = X_train.answerCode.to_numpy()\n",
    "X_valid = data[data.userID.isin(valid_user)==True]\n",
    "y_valid = X_valid.answerCode.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92186f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, max_iter=500)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model01.fit(X_train[FEATS], y_train)\n",
    "model02.fit(X_train[FEATS], y_train)\n",
    "model03.fit(X_train[FEATS], y_train)\n",
    "model04.fit(X_train[FEATS], y_train)\n",
    "model05.fit(X_train[FEATS], y_train)\n",
    "model06.fit(X_train[FEATS], y_train)\n",
    "model07.fit(X_train[FEATS], y_train)\n",
    "model08.fit(X_train[FEATS], y_train)\n",
    "model09.fit(X_train[FEATS], y_train)\n",
    "model10.fit(X_train[FEATS], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c404f1b8-04c6-49bf-843b-3f3485fd513a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc : 0.7634685545926725\n",
      "acc : 0.730521972938819\n",
      "precision : 0.755321754446303\n",
      "recall : 0.8708402174892608\n",
      "AUC LR1:None \n",
      "auc : 0.7637364584771221\n",
      "acc : 0.7305140994500368\n",
      "precision : 0.7538482262668967\n",
      "recall : 0.8741686442969149\n",
      "AUC LR2:None \n",
      "auc : 0.763537304208074\n",
      "acc : 0.7303133254860895\n",
      "precision : 0.7549750596174073\n",
      "recall : 0.8711526330018925\n",
      "AUC LR3:None \n",
      "auc : 0.7639358738617359\n",
      "acc : 0.7304944157280812\n",
      "precision : 0.7567740380079874\n",
      "recall : 0.8675177986722341\n",
      "AUC LR4:None \n",
      "auc : 0.763535739984506\n",
      "acc : 0.7306991264364197\n",
      "precision : 0.7554083908213668\n",
      "recall : 0.8710444891705968\n",
      "AUC LR5:None \n",
      "auc : 0.7649024244130227\n",
      "acc : 0.7297700547601145\n",
      "precision : 0.757305972112602\n",
      "recall : 0.8647060590585479\n",
      "AUC LR6:None \n",
      "auc : 0.7635235407558321\n",
      "acc : 0.7305574036383392\n",
      "precision : 0.7552747012305031\n",
      "recall : 0.8710264651987143\n",
      "AUC LR7:None \n",
      "auc : 0.7635758017396683\n",
      "acc : 0.7304196175846498\n",
      "precision : 0.7550015357304611\n",
      "recall : 0.8713328727207186\n",
      "AUC LR8:None \n",
      "auc : 0.7635076965432128\n",
      "acc : 0.7306243282929883\n",
      "precision : 0.755283074887619\n",
      "recall : 0.87115864099252\n",
      "AUC LR9:None \n",
      "auc : 0.7634656917891176\n",
      "acc : 0.7305298464276013\n",
      "precision : 0.7553163217983524\n",
      "recall : 0.8708702574423984\n",
      "AUC LR0:None \n"
     ]
    }
   ],
   "source": [
    "valid_predict01 = model01.predict_proba(X_valid[FEATS])[:,-1]\n",
    "valid_predict02 = model02.predict_proba(X_valid[FEATS])[:,-1]\n",
    "valid_predict03 = model03.predict_proba(X_valid[FEATS])[:,-1]\n",
    "valid_predict04 = model04.predict_proba(X_valid[FEATS])[:,-1]\n",
    "valid_predict05 = model05.predict_proba(X_valid[FEATS])[:,-1]\n",
    "valid_predict06 = model06.predict_proba(X_valid[FEATS])[:,-1]\n",
    "valid_predict07 = model07.predict_proba(X_valid[FEATS])[:,-1]\n",
    "valid_predict08 = model08.predict_proba(X_valid[FEATS])[:,-1]\n",
    "valid_predict09 = model09.predict_proba(X_valid[FEATS])[:,-1]\n",
    "valid_predict10 = model10.predict_proba(X_valid[FEATS])[:,-1]\n",
    "\n",
    "# item_id2idx는 train에서 사용한 것을 다시 사용한다.\n",
    "test = pd.read_pickle('/opt/ml/level2-dkt-level2-recsys-08/data_pkl/test_data-1.pkl')\n",
    "test = test[test.answerCode==-1]\n",
    "\n",
    "test_predict01 = model01.predict_proba(test[FEATS])[:,-1]\n",
    "test_predict02 = model02.predict_proba(test[FEATS])[:,-1]\n",
    "test_predict03 = model03.predict_proba(test[FEATS])[:,-1]\n",
    "test_predict04 = model04.predict_proba(test[FEATS])[:,-1]\n",
    "test_predict05 = model05.predict_proba(test[FEATS])[:,-1]\n",
    "test_predict06 = model06.predict_proba(test[FEATS])[:,-1]\n",
    "test_predict07 = model07.predict_proba(test[FEATS])[:,-1]\n",
    "test_predict08 = model08.predict_proba(test[FEATS])[:,-1]\n",
    "test_predict09 = model09.predict_proba(test[FEATS])[:,-1]\n",
    "test_predict10 = model10.predict_proba(test[FEATS])[:,-1]\n",
    "\n",
    "\n",
    "print(\"AUC LR1:{} \".format(get_metric(y_valid, np.array(valid_predict01))))\n",
    "print(\"AUC LR2:{} \".format(get_metric(y_valid, np.array(valid_predict02))))\n",
    "print(\"AUC LR3:{} \".format(get_metric(y_valid, np.array(valid_predict03))))\n",
    "print(\"AUC LR4:{} \".format(get_metric(y_valid, np.array(valid_predict04))))\n",
    "print(\"AUC LR5:{} \".format(get_metric(y_valid, np.array(valid_predict05))))\n",
    "print(\"AUC LR6:{} \".format(get_metric(y_valid, np.array(valid_predict06))))\n",
    "print(\"AUC LR7:{} \".format(get_metric(y_valid, np.array(valid_predict07))))\n",
    "print(\"AUC LR8:{} \".format(get_metric(y_valid, np.array(valid_predict08))))\n",
    "print(\"AUC LR9:{} \".format(get_metric(y_valid, np.array(valid_predict09))))\n",
    "print(\"AUC LR0:{} \".format(get_metric(y_valid, np.array(valid_predict10))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3adde4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_valid = X_valid[FEATS].copy()\n",
    "new_valid.loc[:,'predict01'] = valid_predict01\n",
    "new_valid.loc[:,'predict02'] = valid_predict02\n",
    "new_valid.loc[:,'predict03'] = valid_predict03\n",
    "new_valid.loc[:,'predict04'] = valid_predict04\n",
    "new_valid.loc[:,'predict05'] = valid_predict05\n",
    "new_valid.loc[:,'predict06'] = valid_predict06\n",
    "new_valid.loc[:,'predict07'] = valid_predict07\n",
    "new_valid.loc[:,'predict08'] = valid_predict08\n",
    "new_valid.loc[:,'predict09'] = valid_predict09\n",
    "new_valid.loc[:,'predict10'] = valid_predict10\n",
    "\n",
    "\n",
    "# valid_tail = new_valid[new_valid.index.isin(X_valid.groupby('userID').tail(1).index)==True]\n",
    "# new_valid = new_valid[new_valid.index.isin(X_valid.groupby('userID').tail(1).index)==False]\n",
    "\n",
    "new_test = test[FEATS].copy()\n",
    "new_test.loc[:,'predict01'] = test_predict01\n",
    "new_test.loc[:,'predict02'] = test_predict02\n",
    "new_test.loc[:,'predict03'] = test_predict03\n",
    "new_test.loc[:,'predict04'] = test_predict04\n",
    "new_test.loc[:,'predict05'] = test_predict05\n",
    "new_test.loc[:,'predict06'] = test_predict06\n",
    "new_test.loc[:,'predict07'] = test_predict07\n",
    "new_test.loc[:,'predict08'] = test_predict08\n",
    "new_test.loc[:,'predict09'] = test_predict09\n",
    "new_test.loc[:,'predict10'] = test_predict10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a9839547",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final = LogisticRegression()\n",
    "Final.fit(new_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c5c2bf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = Final.predict_proba(new_test)[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "99c91d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, datetime, timezone, timedelta\n",
    "\n",
    "KST = timezone(timedelta(hours=9))\n",
    "time_record = datetime.now(KST)\n",
    "_day = str(time_record)[:10]\n",
    "_time = str(time_record.time())[:8]\n",
    "now_time = _day+'_'+_time\n",
    "\n",
    "\n",
    "test_to_csv(preds, f'Blending_LR_{now_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28df509b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
