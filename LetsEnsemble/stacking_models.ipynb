{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "import lightgbm as lgb\n",
    "from dataset import custom_train_test_split, make_dataset\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import pandas as pd\n",
    "\n",
    "from vecstack import stacking\n",
    "\n",
    "\n",
    "dtype = {\n",
    "    'userID': 'int16',\n",
    "    'answerCode': 'int8',\n",
    "    'KnowledgeTag': 'int16'\n",
    "}\n",
    "\n",
    "def test_to_csv(preds, name:str):\n",
    "    result = []\n",
    "    for n,i in enumerate(preds):\n",
    "        row = {}    \n",
    "        row['id'] = n\n",
    "        row['prediction'] = i\n",
    "        result.append(row)\n",
    "    from datetime import date, datetime, timezone, timedelta\n",
    "\n",
    "    KST = timezone(timedelta(hours=9)); time_record = datetime.now(KST); _day = str(time_record)[:10]; _time = str(time_record.time())[:8]; now_time = _day+'_'+_time\n",
    "\n",
    "    pd.DataFrame(result).to_csv(f'/opt/ml/level2-dkt-level2-recsys-08/LetsEnsemble/output/{name}_{now_time}.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = pd.read_pickle('/opt/ml/level2-dkt-level2-recsys-08/data_pkl/all.pkl')\n",
    "train_data = pd.read_pickle('/opt/ml/level2-dkt-level2-recsys-08/data_pkl/all.pkl')\n",
    "\n",
    "train, valid = custom_train_test_split(train_data)\n",
    "y_train, x_train, y_valid, x_valid = make_dataset(train, valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_pickle('/opt/ml/level2-dkt-level2-recsys-08/data_pkl/test_data.pkl')\n",
    "test_data = test_data[test_data.answerCode==-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Cat Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "cate_cols = [\n",
    "            'assessmentItemID',\n",
    "            'testId',\n",
    "            'KnowledgeTag',\n",
    "            'hour',\n",
    "            'dow',\n",
    "            # 'i_head',\n",
    "            # 'i_mid',\n",
    "            # 'i_tail',\n",
    "]\n",
    "cont_cols = [                        \n",
    "            'user_correct_answer',\n",
    "            'user_total_answer',\n",
    "            'user_acc',            \n",
    "            't_elapsed',            \n",
    "            'cum_correct',\n",
    "            'last_problem',\n",
    "            'head_term',\n",
    "            # 'left_asymptote',\n",
    "            'elo_prob',\n",
    "            'pkt',\n",
    "            'u_head_mean',\n",
    "            'u_head_count',\n",
    "            'u_head_std',\n",
    "            'u_head_elapsed',\n",
    "            'i_mid_elapsed',\n",
    "            'i_mid_mean',\n",
    "            'i_mid_std',\n",
    "            'i_mid_sum',\n",
    "            'i_mid_count',\n",
    "            'i_mid_tag_count',\n",
    "            # 'assessment_mean',\n",
    "            # 'assessment_sum',\n",
    "            # 'assessment_std',\n",
    "            'tag_mean',\n",
    "            'tag_sum',\n",
    "            # 'tag_std',\n",
    "            'tail_mean',\n",
    "            'tail_sum',\n",
    "            # 'tail_std',\n",
    "            'hour_mean',\n",
    "            'hour_sum',\n",
    "            # 'hour_std',\n",
    "            'dow_mean',\n",
    "            'dow_sum',\n",
    "            # 'dow_std',\n",
    "            'tag_elapsed',\n",
    "            'tag_elapsed_o',\n",
    "            'tag_elapsed_x',\n",
    "            'assessment_elapsed',\n",
    "            'assessment_elapsed_o',\n",
    "            'assessment_elapsed_x',\n",
    "            'tail_elapsed',\n",
    "            'tail_elapsed_o',\n",
    "            'tail_elapsed_x'\n",
    "            ]\n",
    "\n",
    "CAT_FEATS = cate_cols + cont_cols\n",
    "\n",
    "catboost_model = CatBoostClassifier().load_model('/opt/ml/level2-dkt-level2-recsys-08/catboost/model_save/catboost2022-05-07_11:21:56.cbm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_cat_cols = ['i_head', 'i_mid','i_tail', 'hour', 'dow']\n",
    "lstm_cont_cols = [                        \n",
    "        'user_correct_answer',\n",
    "        'user_total_answer',\n",
    "        'user_acc',            \n",
    "        't_elapsed',            \n",
    "        'cum_correct',\n",
    "        'last_problem',\n",
    "        'head_term',\n",
    "        # 'left_asymptote',\n",
    "        'elo_prob',\n",
    "        'pkt',\n",
    "        'u_head_mean',\n",
    "        'u_head_count',\n",
    "        'u_head_std',\n",
    "        'u_head_elapsed',\n",
    "        'i_mid_elapsed',\n",
    "        'i_mid_mean',\n",
    "        'i_mid_std',\n",
    "        'i_mid_sum',\n",
    "        'i_mid_count',\n",
    "        'i_mid_tag_count',\n",
    "        'assessment_mean',\n",
    "        'assessment_sum',\n",
    "        # 'assessment_std',\n",
    "        'tag_mean',\n",
    "        'tag_sum',\n",
    "        # 'tag_std',\n",
    "        'tail_mean',\n",
    "        'tail_sum',\n",
    "        # 'tail_std',\n",
    "        'hour_mean',\n",
    "        'hour_sum',\n",
    "        # 'hour_std',\n",
    "        'dow_mean',\n",
    "        'dow_sum',\n",
    "        # 'dow_std',\n",
    "        'tag_elapsed',\n",
    "        'tag_elapsed_o',\n",
    "        'tag_elapsed_x',\n",
    "        'assessment_elapsed',\n",
    "        'assessment_elapsed_o',\n",
    "        'assessment_elapsed_x',\n",
    "        'tail_elapsed',\n",
    "        'tail_elapsed_o',\n",
    "        'tail_elapsed_x']\n",
    "\n",
    "LGBM_FEATS = lstm_cat_cols + lstm_cont_cols\n",
    "\n",
    "import lightgbm as lgb\n",
    "lgbm_model = lgb.Booster(model_file='/opt/ml/level2-dkt-level2-recsys-08/lgbm/best_model/model_best.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8604425834937618"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catboost_preds = catboost_model.predict(x_valid[CAT_FEATS], prediction_type='Probability')[:,1]\n",
    "roc_auc_score(y_valid, catboost_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8981938435292222"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_preds = lgbm_model.predict(x_valid[LGBM_FEATS])\n",
    "roc_auc_score(y_valid, lgbm_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = np.array([catboost_preds, lgbm_preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1488)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1488, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = np.transpose(new_data)\n",
    "new_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 781, number of negative: 707\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1488, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.524866 -> initscore=0.099544\n",
      "[LightGBM] [Info] Start training from score 0.099544\n"
     ]
    }
   ],
   "source": [
    "final_model = lgb.train(\n",
    "        {   \n",
    "        'boosting': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        # 'max_depth' : 10,\n",
    "        # 'num_leaves' : 6,\n",
    "        'metric' : 'binary_logloss',\n",
    "        'force_col_wise' : True,\n",
    "        'learning_rate' : 0.01,\n",
    "        },\n",
    "        lgb.Dataset(new_data, y_valid),  \n",
    "        \n",
    "\n",
    "        )\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_preds = final_model.predict(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9313894166076568"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_valid, new_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_catboost_preds = catboost_model.predict(test_data[CAT_FEATS], prediction_type='Probability')[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lgbm_preds = lgbm_model.predict(test_data[LGBM_FEATS])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = np.array([test_catboost_preds, test_lgbm_preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(744, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds = np.transpose(test_preds)\n",
    "test_preds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final_model 통과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_preds = final_model.predict(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_to_csv(new_preds,'ensemble')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
