{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92d257cd-824a-4921-8b21-c14bada43824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/sarmat/lgbm-stacking-example/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1cc2c9a-80ee-4932-b759-7f49c34b9ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import RocCurveDisplay, accuracy_score, roc_auc_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from dataset import custom_train_test_split, make_dataset\n",
    "\n",
    "def get_metric(targets, preds):\n",
    "    auc = roc_auc_score(targets, preds)\n",
    "    acc = accuracy_score(targets, np.where(preds >= 0.5, 1, 0))\n",
    "    precsion = precision_score(targets, np.where(preds >= 0.5, 1, 0))\n",
    "    recall = recall_score(targets, np.where(preds >= 0.5, 1, 0))\n",
    "    F1_score = f1_score(targets, np.where(preds >= 0.5, 1, 0))\n",
    "\n",
    "    return auc, acc, precsion, recall, F1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84f4ceb8-7f94-43ca-90e5-1fa66095051c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "param1 = {   \n",
    "            'boosting': 'gbdt',\n",
    "            'objective': 'binary',\n",
    "            'num_leaves' : 44,\n",
    "            'metric' : 'binary_logloss',\n",
    "            'learning_rate' : 0.12\n",
    "            \n",
    "            }\n",
    "\n",
    "param2 = {   \n",
    "            'boosting': 'gbdt', \n",
    "            'objective': 'binary',\n",
    "            'num_leaves' : 46,\n",
    "            'metric' : 'binary_logloss',\n",
    "            'learning_rate' : 0.11\n",
    "            }\n",
    "\n",
    "param3 = {   \n",
    "            'boosting': 'gbdt',\n",
    "            'objective': 'binary',\n",
    "            'num_leaves' : 48,\n",
    "            'metric' : 'binary_logloss',\n",
    "            'learning_rate' : 0.10\n",
    "            }\n",
    "\n",
    "param4 = {   \n",
    "            'boosting': 'gbdt',\n",
    "            'objective': 'binary',\n",
    "            'num_leaves' : 50,\n",
    "            'metric' : 'auc',\n",
    "            'learning_rate' : 0.09\n",
    "            \n",
    "            }\n",
    "\n",
    "param5 = {   \n",
    "            'boosting': 'gbdt',\n",
    "            'objective': 'binary',\n",
    "            'num_leaves' : 52,\n",
    "            'metric' : 'binary_logloss',\n",
    "            'learning_rate' : 0.08\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee7f6473-3745-4b22-9fbd-f6dfe18b4a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['i_head', 'i_mid','i_tail', 'hour', 'dow']\n",
    "cont_cols = [                        \n",
    "        'user_correct_answer',\n",
    "        'user_total_answer',\n",
    "        'user_acc',            \n",
    "        't_elapsed',            \n",
    "        'cum_correct',\n",
    "        'last_problem',\n",
    "        'head_term',\n",
    "        # 'left_asymptote',\n",
    "        'elo_prob',\n",
    "        'pkt',\n",
    "        'u_head_mean',\n",
    "        'u_head_count',\n",
    "        'u_head_std',\n",
    "        'u_head_elapsed',\n",
    "        'i_mid_elapsed',\n",
    "        'i_mid_mean',\n",
    "        'i_mid_std',\n",
    "        'i_mid_sum',\n",
    "        'i_mid_count',\n",
    "        'i_mid_tag_count',\n",
    "        'assessment_mean',\n",
    "        'assessment_sum',\n",
    "        # 'assessment_std',\n",
    "        'tag_mean',\n",
    "        'tag_sum',\n",
    "        # 'tag_std',\n",
    "        'tail_mean',\n",
    "        'tail_sum',\n",
    "        # 'tail_std',\n",
    "        'hour_mean',\n",
    "        'hour_sum',\n",
    "        # 'hour_std',\n",
    "        'dow_mean',\n",
    "        'dow_sum',\n",
    "        # 'dow_std',\n",
    "        'tag_elapsed',\n",
    "        'tag_elapsed_o',\n",
    "        'tag_elapsed_x',\n",
    "        'assessment_elapsed',\n",
    "        'assessment_elapsed_o',\n",
    "        'assessment_elapsed_x',\n",
    "        'tail_elapsed',\n",
    "        'tail_elapsed_o',\n",
    "        'tail_elapsed_x']\n",
    "\n",
    "FEATS = cat_cols + cont_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9884ba83-6b5d-425b-be04-c0000a1f3c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle('/opt/ml/level2-dkt-level2-recsys-08/data_pkl/all.pkl')\n",
    "y = train.answerCode\n",
    "# train, test = custom_train_test_split(train_data)\n",
    "# y_train, train, y_test, test = make_dataset(train, test)\n",
    "test = pd.read_pickle('/opt/ml/level2-dkt-level2-recsys-08/data_pkl/test_data.pkl')\n",
    "test = test[test.answerCode==-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c404f1b8-04c6-49bf-843b-3f3485fd513a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.8/site-packages/lightgbm/basic.py:2068: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['dow', 'hour', 'i_head', 'i_mid', 'i_tail']\n",
      "  _log_warning('categorical_feature in Dataset is overridden.\\n'\n",
      "/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1102675, number of negative: 581295\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041934 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6623\n",
      "[LightGBM] [Info] Number of data points in the train set: 1683970, number of used features: 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/opt/conda/lib/python3.8/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654807 -> initscore=0.640236\n",
      "[LightGBM] [Info] Start training from score 0.640236\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.428653\n",
      "[200]\tvalid_0's binary_logloss: 0.427123\n",
      "[300]\tvalid_0's binary_logloss: 0.426917\n",
      "[400]\tvalid_0's binary_logloss: 0.426658\n",
      "[500]\tvalid_0's binary_logloss: 0.426563\n",
      "Early stopping, best iteration is:\n",
      "[481]\tvalid_0's binary_logloss: 0.426511\n",
      "[LightGBM] [Info] Number of positive: 1102675, number of negative: 581295\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.037941 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6623\n",
      "[LightGBM] [Info] Number of data points in the train set: 1683970, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654807 -> initscore=0.640236\n",
      "[LightGBM] [Info] Start training from score 0.640236\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.428739\n",
      "[200]\tvalid_0's binary_logloss: 0.427128\n",
      "[300]\tvalid_0's binary_logloss: 0.42678\n",
      "[400]\tvalid_0's binary_logloss: 0.42665\n",
      "Early stopping, best iteration is:\n",
      "[377]\tvalid_0's binary_logloss: 0.426607\n",
      "[LightGBM] [Info] Number of positive: 1102675, number of negative: 581295\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041832 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6623\n",
      "[LightGBM] [Info] Number of data points in the train set: 1683970, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654807 -> initscore=0.640236\n",
      "[LightGBM] [Info] Start training from score 0.640236\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.429101\n",
      "[200]\tvalid_0's binary_logloss: 0.427154\n",
      "[300]\tvalid_0's binary_logloss: 0.426746\n",
      "[400]\tvalid_0's binary_logloss: 0.426586\n",
      "[500]\tvalid_0's binary_logloss: 0.426446\n",
      "[600]\tvalid_0's binary_logloss: 0.426417\n",
      "[700]\tvalid_0's binary_logloss: 0.426372\n",
      "[800]\tvalid_0's binary_logloss: 0.426344\n",
      "Early stopping, best iteration is:\n",
      "[780]\tvalid_0's binary_logloss: 0.4263\n",
      "[LightGBM] [Info] Number of positive: 1102675, number of negative: 581295\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044089 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6623\n",
      "[LightGBM] [Info] Number of data points in the train set: 1683970, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654807 -> initscore=0.640236\n",
      "[LightGBM] [Info] Start training from score 0.640236\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.863775\n",
      "[200]\tvalid_0's auc: 0.8651\n",
      "[300]\tvalid_0's auc: 0.86531\n",
      "[400]\tvalid_0's auc: 0.865502\n",
      "[500]\tvalid_0's auc: 0.865564\n",
      "[600]\tvalid_0's auc: 0.865563\n",
      "Early stopping, best iteration is:\n",
      "[554]\tvalid_0's auc: 0.865597\n",
      "[LightGBM] [Info] Number of positive: 1102675, number of negative: 581295\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038702 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6623\n",
      "[LightGBM] [Info] Number of data points in the train set: 1683970, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654807 -> initscore=0.640236\n",
      "[LightGBM] [Info] Start training from score 0.640236\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.429606\n",
      "[200]\tvalid_0's binary_logloss: 0.427184\n",
      "[300]\tvalid_0's binary_logloss: 0.426594\n",
      "[400]\tvalid_0's binary_logloss: 0.426371\n",
      "[500]\tvalid_0's binary_logloss: 0.426259\n",
      "[600]\tvalid_0's binary_logloss: 0.426203\n",
      "[700]\tvalid_0's binary_logloss: 0.42609\n",
      "[800]\tvalid_0's binary_logloss: 0.426027\n",
      "Early stopping, best iteration is:\n",
      "[779]\tvalid_0's binary_logloss: 0.426011\n",
      "AUC LGB1:0.8653660871707465 \n",
      "AUC LGB2:0.8653086935449419 \n",
      "AUC LGB3:0.8654923739244257 \n",
      "AUC LGB4:0.865596906935289 \n",
      "AUC LGB5:0.86566353813516 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.8/site-packages/lightgbm/basic.py:2068: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['dow', 'hour', 'i_head', 'i_mid', 'i_tail']\n",
      "  _log_warning('categorical_feature in Dataset is overridden.\\n'\n",
      "/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1101885, number of negative: 582086\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.037388 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6622\n",
      "[LightGBM] [Info] Number of data points in the train set: 1683971, number of used features: 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/opt/conda/lib/python3.8/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654337 -> initscore=0.638159\n",
      "[LightGBM] [Info] Start training from score 0.638159\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.427742\n",
      "[200]\tvalid_0's binary_logloss: 0.426465\n",
      "[300]\tvalid_0's binary_logloss: 0.426091\n",
      "[400]\tvalid_0's binary_logloss: 0.426032\n",
      "[500]\tvalid_0's binary_logloss: 0.426026\n",
      "Early stopping, best iteration is:\n",
      "[433]\tvalid_0's binary_logloss: 0.425933\n",
      "[LightGBM] [Info] Number of positive: 1101885, number of negative: 582086\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044711 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6622\n",
      "[LightGBM] [Info] Number of data points in the train set: 1683971, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654337 -> initscore=0.638159\n",
      "[LightGBM] [Info] Start training from score 0.638159\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.428113\n",
      "[200]\tvalid_0's binary_logloss: 0.426552\n",
      "[300]\tvalid_0's binary_logloss: 0.426157\n",
      "[400]\tvalid_0's binary_logloss: 0.425894\n",
      "[500]\tvalid_0's binary_logloss: 0.425894\n",
      "Early stopping, best iteration is:\n",
      "[464]\tvalid_0's binary_logloss: 0.425809\n",
      "[LightGBM] [Info] Number of positive: 1101885, number of negative: 582086\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039796 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6622\n",
      "[LightGBM] [Info] Number of data points in the train set: 1683971, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654337 -> initscore=0.638159\n",
      "[LightGBM] [Info] Start training from score 0.638159\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.428112\n",
      "[200]\tvalid_0's binary_logloss: 0.426345\n",
      "[300]\tvalid_0's binary_logloss: 0.425721\n",
      "[400]\tvalid_0's binary_logloss: 0.425479\n",
      "[500]\tvalid_0's binary_logloss: 0.425339\n",
      "[600]\tvalid_0's binary_logloss: 0.425387\n",
      "Early stopping, best iteration is:\n",
      "[521]\tvalid_0's binary_logloss: 0.425317\n",
      "[LightGBM] [Info] Number of positive: 1101885, number of negative: 582086\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.213313 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6622\n",
      "[LightGBM] [Info] Number of data points in the train set: 1683971, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654337 -> initscore=0.638159\n",
      "[LightGBM] [Info] Start training from score 0.638159\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.863844\n",
      "[200]\tvalid_0's auc: 0.865192\n",
      "[300]\tvalid_0's auc: 0.865475\n",
      "[400]\tvalid_0's auc: 0.865614\n",
      "[500]\tvalid_0's auc: 0.865667\n",
      "[600]\tvalid_0's auc: 0.865692\n",
      "Early stopping, best iteration is:\n",
      "[578]\tvalid_0's auc: 0.865722\n",
      "[LightGBM] [Info] Number of positive: 1101885, number of negative: 582086\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.170728 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6622\n",
      "[LightGBM] [Info] Number of data points in the train set: 1683971, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654337 -> initscore=0.638159\n",
      "[LightGBM] [Info] Start training from score 0.638159\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.428925\n",
      "[200]\tvalid_0's binary_logloss: 0.426455\n",
      "[300]\tvalid_0's binary_logloss: 0.425888\n",
      "[400]\tvalid_0's binary_logloss: 0.425626\n",
      "[500]\tvalid_0's binary_logloss: 0.425459\n",
      "[600]\tvalid_0's binary_logloss: 0.4253\n",
      "[700]\tvalid_0's binary_logloss: 0.425179\n",
      "[800]\tvalid_0's binary_logloss: 0.425199\n",
      "Early stopping, best iteration is:\n",
      "[761]\tvalid_0's binary_logloss: 0.425162\n",
      "AUC LGB1:0.8654196158032811 \n",
      "AUC LGB2:0.8655222027679867 \n",
      "AUC LGB3:0.8658420000256191 \n",
      "AUC LGB4:0.8657216602057172 \n",
      "AUC LGB5:0.8659227252168711 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.8/site-packages/lightgbm/basic.py:2068: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['dow', 'hour', 'i_head', 'i_mid', 'i_tail']\n",
      "  _log_warning('categorical_feature in Dataset is overridden.\\n'\n",
      "/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1102616, number of negative: 581355\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.037098 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6623\n",
      "[LightGBM] [Info] Number of data points in the train set: 1683971, number of used features: 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/opt/conda/lib/python3.8/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654771 -> initscore=0.640079\n",
      "[LightGBM] [Info] Start training from score 0.640079\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.428142\n",
      "[200]\tvalid_0's binary_logloss: 0.426663\n",
      "[300]\tvalid_0's binary_logloss: 0.426313\n",
      "[400]\tvalid_0's binary_logloss: 0.426148\n",
      "[500]\tvalid_0's binary_logloss: 0.426117\n",
      "Early stopping, best iteration is:\n",
      "[454]\tvalid_0's binary_logloss: 0.426085\n",
      "[LightGBM] [Info] Number of positive: 1102616, number of negative: 581355\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039127 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6623\n",
      "[LightGBM] [Info] Number of data points in the train set: 1683971, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654771 -> initscore=0.640079\n",
      "[LightGBM] [Info] Start training from score 0.640079\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.428483\n",
      "[200]\tvalid_0's binary_logloss: 0.426866\n",
      "[300]\tvalid_0's binary_logloss: 0.426427\n",
      "[400]\tvalid_0's binary_logloss: 0.42631\n",
      "[500]\tvalid_0's binary_logloss: 0.426287\n",
      "Early stopping, best iteration is:\n",
      "[490]\tvalid_0's binary_logloss: 0.426259\n",
      "[LightGBM] [Info] Number of positive: 1102616, number of negative: 581355\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039718 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6623\n",
      "[LightGBM] [Info] Number of data points in the train set: 1683971, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654771 -> initscore=0.640079\n",
      "[LightGBM] [Info] Start training from score 0.640079\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.428601\n",
      "[200]\tvalid_0's binary_logloss: 0.426801\n",
      "[300]\tvalid_0's binary_logloss: 0.426513\n",
      "[400]\tvalid_0's binary_logloss: 0.426252\n",
      "[500]\tvalid_0's binary_logloss: 0.426097\n",
      "[600]\tvalid_0's binary_logloss: 0.426034\n",
      "[700]\tvalid_0's binary_logloss: 0.425833\n",
      "[800]\tvalid_0's binary_logloss: 0.42594\n",
      "Early stopping, best iteration is:\n",
      "[705]\tvalid_0's binary_logloss: 0.42582\n",
      "[LightGBM] [Info] Number of positive: 1102616, number of negative: 581355\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052943 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6623\n",
      "[LightGBM] [Info] Number of data points in the train set: 1683971, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654771 -> initscore=0.640079\n",
      "[LightGBM] [Info] Start training from score 0.640079\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.863984\n",
      "[200]\tvalid_0's auc: 0.865346\n",
      "[300]\tvalid_0's auc: 0.865636\n",
      "[400]\tvalid_0's auc: 0.865755\n",
      "[500]\tvalid_0's auc: 0.865867\n",
      "[600]\tvalid_0's auc: 0.865917\n",
      "[700]\tvalid_0's auc: 0.865923\n",
      "[800]\tvalid_0's auc: 0.865942\n",
      "Early stopping, best iteration is:\n",
      "[758]\tvalid_0's auc: 0.865971\n",
      "[LightGBM] [Info] Number of positive: 1102616, number of negative: 581355\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041110 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6623\n",
      "[LightGBM] [Info] Number of data points in the train set: 1683971, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654771 -> initscore=0.640079\n",
      "[LightGBM] [Info] Start training from score 0.640079\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.429366\n",
      "[200]\tvalid_0's binary_logloss: 0.426899\n",
      "[300]\tvalid_0's binary_logloss: 0.426396\n",
      "[400]\tvalid_0's binary_logloss: 0.426136\n",
      "[500]\tvalid_0's binary_logloss: 0.425958\n",
      "[600]\tvalid_0's binary_logloss: 0.42575\n",
      "[700]\tvalid_0's binary_logloss: 0.425667\n",
      "[800]\tvalid_0's binary_logloss: 0.425594\n",
      "Early stopping, best iteration is:\n",
      "[740]\tvalid_0's binary_logloss: 0.425586\n",
      "AUC LGB1:0.8657042322349561 \n",
      "AUC LGB2:0.8656098988333135 \n",
      "AUC LGB3:0.8658445909722999 \n",
      "AUC LGB4:0.8659706557668296 \n",
      "AUC LGB5:0.8660176738428672 \n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=3, random_state = 42,shuffle = True)\n",
    "\n",
    "oof_clf1 = np.zeros(len(train))\n",
    "oof_clf2 = np.zeros(len(train))\n",
    "oof_clf3 = np.zeros(len(train))\n",
    "oof_clf4 = np.zeros(len(train))\n",
    "oof_clf5 = np.zeros(len(train))\n",
    "\n",
    "oof_clf1_t = np.zeros(len(test))\n",
    "oof_clf2_t = np.zeros(len(test))\n",
    "oof_clf3_t = np.zeros(len(test))\n",
    "oof_clf4_t = np.zeros(len(test))\n",
    "oof_clf5_t = np.zeros(len(test))\n",
    "\n",
    "for (trn_idx, val_idx),test_val_idx in zip(kf.split(train.values, y.values),kf.split(test.values)):\n",
    "        test_val_idx = test_val_idx[0]\n",
    "        \n",
    "        lgb_train = lgb.Dataset(train[FEATS].iloc[trn_idx], label = y.iloc[trn_idx]) \n",
    "        lgb_valid = lgb.Dataset(train[FEATS].iloc[val_idx], label = y.iloc[val_idx]) \n",
    "        \n",
    "        model1 = lgb.train(param1, lgb_train, 1000, valid_sets=[lgb_valid], early_stopping_rounds=100,verbose_eval=100, categorical_feature = cat_cols)\n",
    "        model2 = lgb.train(param2, lgb_train, 10000, valid_sets=[lgb_valid], early_stopping_rounds=100,verbose_eval=100, categorical_feature = cat_cols)\n",
    "        model3 = lgb.train(param3, lgb_train, 10000, valid_sets=[lgb_valid], early_stopping_rounds=100,verbose_eval=100, categorical_feature = cat_cols)\n",
    "        model4 = lgb.train(param4, lgb_train, 10000, valid_sets=[lgb_valid], early_stopping_rounds=100,verbose_eval=100, categorical_feature = cat_cols)\n",
    "        model5 = lgb.train(param5, lgb_train, 10000, valid_sets=[lgb_valid], early_stopping_rounds=100,verbose_eval=100, categorical_feature = cat_cols)            \n",
    "        \n",
    "        oof_clf1[val_idx] = model1.predict(train[FEATS].iloc[val_idx])\n",
    "        oof_clf2[val_idx] = model2.predict(train[FEATS].iloc[val_idx])\n",
    "        oof_clf3[val_idx] = model3.predict(train[FEATS].iloc[val_idx])\n",
    "        oof_clf4[val_idx] = model4.predict(train[FEATS].iloc[val_idx])\n",
    "        oof_clf5[val_idx] = model5.predict(train[FEATS].iloc[val_idx])\n",
    "        \n",
    "        oof_clf1_t[test_val_idx] = model1.predict(test[FEATS].iloc[test_val_idx])\n",
    "        oof_clf2_t[test_val_idx] = model2.predict(test[FEATS].iloc[test_val_idx])\n",
    "        oof_clf3_t[test_val_idx] = model3.predict(test[FEATS].iloc[test_val_idx])\n",
    "        oof_clf4_t[test_val_idx] = model4.predict(test[FEATS].iloc[test_val_idx])\n",
    "        oof_clf5_t[test_val_idx] = model5.predict(test[FEATS].iloc[test_val_idx])\n",
    "        \n",
    "        # print('Fold no: {}'.format(fold_))\n",
    "        print(\"AUC LGB1:{} \".format(metrics.roc_auc_score(y.iloc[val_idx], oof_clf1[val_idx])))\n",
    "        print(\"AUC LGB2:{} \".format(metrics.roc_auc_score(y.iloc[val_idx], oof_clf2[val_idx])))\n",
    "        print(\"AUC LGB3:{} \".format(metrics.roc_auc_score(y.iloc[val_idx], oof_clf3[val_idx])))\n",
    "        print(\"AUC LGB4:{} \".format(metrics.roc_auc_score(y.iloc[val_idx], oof_clf4[val_idx])))\n",
    "        print(\"AUC LGB5:{} \".format(metrics.roc_auc_score(y.iloc[val_idx], oof_clf5[val_idx]))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fa96f2b-c9b8-482e-9c5a-bf6d57f10479",
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_train = pd.DataFrame( {\n",
    "        'LGBM1': oof_clf1.ravel(),\n",
    "        'LGBM2': oof_clf2.ravel(),\n",
    "        'LGBM3': oof_clf3.ravel(),\n",
    "        'LGBM4' :oof_clf4.ravel(),\n",
    "        'LGBM5': oof_clf5.ravel(),\n",
    "    })\n",
    "\n",
    "Final_test = pd.DataFrame( {\n",
    "        'LGBM1': oof_clf1_t.ravel(),\n",
    "        'LGBM2': oof_clf2_t.ravel(),\n",
    "        'LGBM3': oof_clf3_t.ravel(),\n",
    "        'LGBM4' :oof_clf4_t.ravel(),\n",
    "        'LGBM5': oof_clf5_t.ravel(),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3b5435a-ab5d-4f37-90d7-0655c15f2da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'objective': 'binary',\n",
    "                 'boosting': 'gbdt',\n",
    "                 'random_state': 42,\n",
    "                 'metric': 'auc',\n",
    "                 'num_threads': -1,\n",
    "                 'learning_rate' : 0.1,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8327116-8598-4455-b695-9d18c7e88675",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1323032, number of negative: 697732\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016958 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 2020764, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654719 -> initscore=0.639846\n",
      "[LightGBM] [Info] Start training from score 0.639846\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's auc: 0.866148\n",
      "[200]\tvalid_0's auc: 0.866132\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's auc: 0.866165\n",
      "AUC LGB1:0.8661645492616501 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1322521, number of negative: 698244\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008243 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 2020765, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654466 -> initscore=0.638726\n",
      "[LightGBM] [Info] Start training from score 0.638726\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's auc: 0.86626\n",
      "[200]\tvalid_0's auc: 0.866238\n",
      "Early stopping, best iteration is:\n",
      "[47]\tvalid_0's auc: 0.866279\n",
      "AUC LGB1:0.8662790724082267 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1323005, number of negative: 697760\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008636 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 2020765, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654705 -> initscore=0.639786\n",
      "[LightGBM] [Info] Start training from score 0.639786\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's auc: 0.866286\n",
      "[200]\tvalid_0's auc: 0.866262\n",
      "Early stopping, best iteration is:\n",
      "[39]\tvalid_0's auc: 0.866304\n",
      "AUC LGB1:0.8663036226942176 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1323025, number of negative: 697740\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006687 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 2020765, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654715 -> initscore=0.639830\n",
      "[LightGBM] [Info] Start training from score 0.639830\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's auc: 0.866391\n",
      "[200]\tvalid_0's auc: 0.866354\n",
      "Early stopping, best iteration is:\n",
      "[61]\tvalid_0's auc: 0.866398\n",
      "AUC LGB1:0.866398157589848 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1322769, number of negative: 697996\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007747 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 2020765, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654588 -> initscore=0.639269\n",
      "[LightGBM] [Info] Start training from score 0.639269\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's auc: 0.866565\n",
      "[200]\tvalid_0's auc: 0.866537\n",
      "Early stopping, best iteration is:\n",
      "[48]\tvalid_0's auc: 0.866582\n",
      "AUC LGB1:0.866582007062134 \n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, random_state = 42,shuffle = True)\n",
    "\n",
    "Final_oof_train = np.zeros(len(train))\n",
    "Final_oof_test = np.zeros(len(test))\n",
    "\n",
    "for (trn_idx, val_idx), test_val_idx in zip(kf.split(Final_train.values, y.values), kf.split(Final_test.values)):\n",
    "        # print(\"fold n°{}\".format(fold_))\n",
    "        test_val_idx = test_val_idx[0]\n",
    "        lgb_train = lgb.Dataset(Final_train.iloc[trn_idx], label = y.iloc[trn_idx])\n",
    "        lgb_valid = lgb.Dataset(Final_train.iloc[val_idx], label = y.iloc[val_idx])\n",
    "        \n",
    "        model = lgb.train(param, lgb_train, 1000, valid_sets=[lgb_valid], early_stopping_rounds=200,verbose_eval=100)\n",
    "                \n",
    "        Final_oof_train[val_idx] = model.predict(Final_train.iloc[val_idx])        \n",
    "        \n",
    "        Final_oof_test[test_val_idx] = model.predict(Final_test.iloc[test_val_idx])\n",
    "        \n",
    "        # print('Fold no: {}'.format(fold_))\n",
    "        print(\"AUC LGB1:{} \".format(metrics.roc_auc_score(y.iloc[val_idx], Final_oof_train[val_idx])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afa5b7cd-378d-4a54-afb9-620b1681b01c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "744"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_oof_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66a99cb3-1a1c-48d4-82b0-652a4f385c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_to_csv(preds, name:str):\n",
    "    \n",
    "    result = []\n",
    "    for n,i in enumerate(preds):\n",
    "        row = {}    \n",
    "        row['id'] = n\n",
    "        row['prediction'] = i\n",
    "        result.append(row)\n",
    "    pd.DataFrame(result).to_csv(f'output/{name}.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e9d7861-8ecc-4520-81bf-6d930f32a634",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, datetime, timezone, timedelta\n",
    "\n",
    "KST = timezone(timedelta(hours=9))\n",
    "time_record = datetime.now(KST)\n",
    "_day = str(time_record)[:10]\n",
    "_time = str(time_record.time())[:8]\n",
    "now_time = _day+'_'+_time\n",
    "\n",
    "test_to_csv(Final_oof_test,f'Stacking_LGBM_{now_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4d3f85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
