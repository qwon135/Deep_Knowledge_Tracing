{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression, ElasticNet, SGDClassifier, MultiTaskElasticNet, BayesianRidge, Lasso, RidgeClassifier, Lars, OrthogonalMatchingPursuit, Ridge,  ARDRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import RocCurveDisplay, accuracy_score, roc_auc_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "from sklearn.decomposition import NMF, PCA, TruncatedSVD\n",
    "import os\n",
    "\n",
    "def get_metric(targets, preds):\n",
    "    auc = roc_auc_score(targets, preds)\n",
    "    acc = accuracy_score(targets, np.where(preds >= 0.5, 1, 0))\n",
    "    precsion = precision_score(targets, np.where(preds >= 0.5, 1, 0))\n",
    "    recall = recall_score(targets, np.where(preds >= 0.5, 1, 0))\n",
    "    F1_score = f1_score(targets, np.where(preds >= 0.5, 1, 0))\n",
    "\n",
    "    print('auc :',auc)\n",
    "    print('acc :',acc)\n",
    "    print('precision :',precsion)\n",
    "    print('recall :',recall)\n",
    "\n",
    "def test_to_csv(preds, name:str):\n",
    "    \n",
    "    result = []\n",
    "    for n,i in enumerate(preds):\n",
    "        row = {}    \n",
    "        row['id'] = n\n",
    "        row['prediction'] = i\n",
    "        result.append(row)\n",
    "    pd.DataFrame(result).to_csv(f'{name}', index=None)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cate_cols = [\n",
    "            # 'assessmentItemID',\n",
    "            # 'testId',\n",
    "            # 'KnowledgeTag',\n",
    "            'hour',\n",
    "            'dow',\n",
    "            'i_head',\n",
    "            'i_mid',\n",
    "            'i_tail',\n",
    "]\n",
    "cont_cols = [                        \n",
    "            'user_correct_answer',\n",
    "            'user_total_answer',\n",
    "            'user_acc',            \n",
    "            't_elapsed',            \n",
    "            'cum_correct',\n",
    "            'last_problem',\n",
    "            'head_term',\n",
    "            # 'left_asymptote',\n",
    "            'elo_prob',\n",
    "            'pkt',\n",
    "            'u_head_mean',\n",
    "            'u_head_count',\n",
    "            'u_head_std',\n",
    "            'u_head_elapsed',\n",
    "            'i_mid_elapsed',\n",
    "            'i_mid_mean',\n",
    "            'i_mid_std',\n",
    "            'i_mid_sum',\n",
    "            'i_mid_count',\n",
    "            'i_mid_tag_count',\n",
    "            'assessment_mean',\n",
    "            'assessment_sum',\n",
    "            # 'assessment_std',\n",
    "            'tag_mean',\n",
    "            'tag_sum',\n",
    "            # 'tag_std',\n",
    "            'tail_mean',\n",
    "            'tail_sum',\n",
    "            # 'tail_std',\n",
    "            'hour_mean',\n",
    "            'hour_sum',\n",
    "            # 'hour_std',\n",
    "            'dow_mean',\n",
    "            'dow_sum',\n",
    "            # 'dow_std',\n",
    "            'tag_elapsed',\n",
    "            'tag_elapsed_o',\n",
    "            'tag_elapsed_x',\n",
    "            'assessment_elapsed',\n",
    "            'assessment_elapsed_o',\n",
    "            'assessment_elapsed_x',\n",
    "            'tail_elapsed',\n",
    "            'tail_elapsed_o',\n",
    "            'tail_elapsed_x'\n",
    "            ]\n",
    "\n",
    "FEATS = cate_cols + cont_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('/opt/ml/level2-dkt-level2-recsys-08/data_pkl/all.pkl')\n",
    "label = data.answerCode.to_numpy()\n",
    "\n",
    "valid_user = pd.read_csv('/opt/ml/input/data/cv_valid_data.csv').userID.unique()\n",
    "test_user = pd.read_csv('/opt/ml/input/data/test_data.csv').userID.unique()\n",
    "\n",
    "train = data[data.userID.isin(valid_user)==False]\n",
    "train = data[data.userID.isin(test_user)==False]\n",
    "\n",
    "X_train = data[FEATS]\n",
    "y_train = data.answerCode\n",
    "X_valid = data[data.userID.isin(valid_user)][FEATS]\n",
    "y_valid = data[data.userID.isin(valid_user)].answerCode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR01 = LogisticRegression(max_iter=500, C= 1)\n",
    "LR02 = LogisticRegression(max_iter=500, C= 2)\n",
    "LR03 = LogisticRegression(max_iter=500, C= 3)\n",
    "LR04 = LogisticRegression(max_iter=500, C= 4)\n",
    "LR05 = LogisticRegression(max_iter=500, C= 5)\n",
    "LR06 = LogisticRegression(max_iter=500, C= 6)\n",
    "LR07 = LogisticRegression(max_iter=500, C= 7)\n",
    "LR08 = LogisticRegression(max_iter=500, C= 8)\n",
    "LR09 = LogisticRegression(max_iter=500, C= 9)\n",
    "LR10 = LogisticRegression(max_iter=500, C= 10)\n",
    "\n",
    "ELASTIC01 = ElasticNet(max_iter=2000, alpha= 0.4, fit_intercept= True)\n",
    "ELASTIC02 = ElasticNet(max_iter=2000, alpha= 0.4, l1_ratio=0.1)\n",
    "ELASTIC03 = ElasticNet(max_iter=2000, alpha= 0.4, l1_ratio=0.9)\n",
    "ELASTIC04 = ElasticNet(max_iter=2000, alpha= 0.6, fit_intercept= True)\n",
    "ELASTIC05 = ElasticNet(max_iter=2000, alpha= 0.6, l1_ratio=0.1)\n",
    "ELASTIC06 = ElasticNet(max_iter=2000, alpha= 0.6, l1_ratio=0.9)\n",
    "ELASTIC07 = ElasticNet(max_iter=2000, alpha= 0.6)\n",
    "ELASTIC08 = ElasticNet(max_iter=2000, alpha= 0.8, fit_intercept= True)11\n",
    "ELASTIC09 = ElasticNet(max_iter=2000, alpha= 0.8, l1_ratio=0.1)\n",
    "ELASTIC10 = ElasticNet(max_iter=2000, alpha= 0.8, l1_ratio=0.9)\n",
    "\n",
    "BR001 = BayesianRidge(tol=0.001, fit_intercept= True)\n",
    "BR002 = BayesianRidge(tol=0.002, fit_intercept= True)\n",
    "BR003 = BayesianRidge(tol=0.003, fit_intercept= True)\n",
    "BR004 = BayesianRidge(tol=0.004, fit_intercept= True)\n",
    "BR005 = BayesianRidge(tol=0.005, fit_intercept= True)\n",
    "BR006 = BayesianRidge(tol=0.006, fit_intercept= True)\n",
    "BR007 = BayesianRidge(tol=0.007, fit_intercept= True)\n",
    "BR008 = BayesianRidge(tol=0.008, fit_intercept= True)\n",
    "BR009 = BayesianRidge(tol=0.009, fit_intercept= True)\n",
    "BR010 = BayesianRidge(tol=0.010, fit_intercept= True)\n",
    "\n",
    "LASSO = Lasso()\n",
    "\n",
    "RIDGE01 = Ridge(alpha= 0.1,)\n",
    "RIDGE02 = Ridge(alpha= 0.2)\n",
    "RIDGE03 = Ridge(alpha= 0.3)\n",
    "RIDGE04 = Ridge(alpha= 0.4)\n",
    "RIDGE05 = Ridge(alpha= 0.5)\n",
    "RIDGE06 = Ridge(alpha= 0.6)\n",
    "RIDGE07 = Ridge(alpha= 0.7)\n",
    "RIDGE08 = Ridge(alpha= 0.8)\n",
    "RIDGE09 = Ridge(alpha= 0.9)\n",
    "RIDGE10 = Ridge(alpha= 1.0)\n",
    "\n",
    "LARS = Lars()\n",
    "\n",
    "OMP = OrthogonalMatchingPursuit()\n",
    "\n",
    "ARD01 = ARDRegression(tol=0.001)\n",
    "ARD02 = ARDRegression(tol=0.002)\n",
    "ARD03 = ARDRegression(tol=0.003)\n",
    "ARD04 = ARDRegression(tol=0.004)\n",
    "ARD05 = ARDRegression(tol=0.005)\n",
    "ARD06 = ARDRegression(tol=0.006)\n",
    "ARD07 = ARDRegression(tol=0.007)\n",
    "ARD08 = ARDRegression(tol=0.008)\n",
    "ARD09 = ARDRegression(tol=0.009)\n",
    "ARD10 = ARDRegression(tol=0.010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ARDRegression(tol=0.01)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR01.fit(X_train, y_train)\n",
    "LR02.fit(X_train, y_train)\n",
    "LR03.fit(X_train, y_train)\n",
    "LR04.fit(X_train, y_train)\n",
    "LR05.fit(X_train, y_train)\n",
    "LR06.fit(X_train, y_train)\n",
    "LR07.fit(X_train, y_train)\n",
    "LR08.fit(X_train, y_train)\n",
    "LR09.fit(X_train, y_train)\n",
    "LR10.fit(X_train, y_train)\n",
    "\n",
    "ELASTIC01.fit(X_train, y_train)\n",
    "ELASTIC02.fit(X_train, y_train)\n",
    "ELASTIC03.fit(X_train, y_train)\n",
    "ELASTIC04.fit(X_train, y_train)\n",
    "ELASTIC05.fit(X_train, y_train)\n",
    "ELASTIC06.fit(X_train, y_train)\n",
    "ELASTIC07.fit(X_train, y_train)\n",
    "ELASTIC08.fit(X_train, y_train)\n",
    "ELASTIC09.fit(X_train, y_train)\n",
    "ELASTIC10.fit(X_train, y_train)\n",
    "\n",
    "BR001.fit(X_train, y_train)\n",
    "BR002.fit(X_train, y_train)\n",
    "BR003.fit(X_train, y_train)\n",
    "BR004.fit(X_train, y_train)\n",
    "BR005.fit(X_train, y_train)\n",
    "BR006.fit(X_train, y_train)\n",
    "BR007.fit(X_train, y_train)\n",
    "BR008.fit(X_train, y_train)\n",
    "BR009.fit(X_train, y_train)\n",
    "BR010.fit(X_train, y_train)\n",
    "\n",
    "LASSO.fit(X_train, y_train)\n",
    "\n",
    "RIDGE01.fit(X_train, y_train)\n",
    "RIDGE02.fit(X_train, y_train)\n",
    "RIDGE03.fit(X_train, y_train)\n",
    "RIDGE04.fit(X_train, y_train)\n",
    "RIDGE05.fit(X_train, y_train)\n",
    "RIDGE06.fit(X_train, y_train)\n",
    "RIDGE07.fit(X_train, y_train)\n",
    "RIDGE08.fit(X_train, y_train)\n",
    "RIDGE09.fit(X_train, y_train)\n",
    "RIDGE10.fit(X_train, y_train)\n",
    "\n",
    "LARS.fit(X_train, y_train)\n",
    "\n",
    "OMP.fit(X_train, y_train)\n",
    "\n",
    "ARD01.fit(X_train, y_train)\n",
    "ARD02.fit(X_train, y_train)\n",
    "ARD03.fit(X_train, y_train)\n",
    "ARD04.fit(X_train, y_train)\n",
    "ARD05.fit(X_train, y_train)\n",
    "ARD06.fit(X_train, y_train)\n",
    "ARD07.fit(X_train, y_train)\n",
    "ARD08.fit(X_train, y_train)\n",
    "ARD09.fit(X_train, y_train)\n",
    "ARD10.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR01_valid = LR01.predict_proba(X_valid)[:,-1]\n",
    "LR02_valid = LR02.predict_proba(X_valid)[:,-1]\n",
    "LR03_valid = LR03.predict_proba(X_valid)[:,-1]\n",
    "LR04_valid = LR04.predict_proba(X_valid)[:,-1]\n",
    "LR05_valid = LR05.predict_proba(X_valid)[:,-1]\n",
    "LR06_valid = LR06.predict_proba(X_valid)[:,-1]\n",
    "LR07_valid = LR07.predict_proba(X_valid)[:,-1]\n",
    "LR08_valid = LR08.predict_proba(X_valid)[:,-1]\n",
    "LR09_valid = LR09.predict_proba(X_valid)[:,-1]\n",
    "LR10_valid = LR10.predict_proba(X_valid)[:,-1]\n",
    "\n",
    "ELASTIC01_valid = ELASTIC01.predict(X_valid)\n",
    "ELASTIC02_valid = ELASTIC02.predict(X_valid)\n",
    "ELASTIC03_valid = ELASTIC03.predict(X_valid)\n",
    "ELASTIC04_valid = ELASTIC04.predict(X_valid)\n",
    "ELASTIC05_valid = ELASTIC05.predict(X_valid)\n",
    "ELASTIC06_valid = ELASTIC06.predict(X_valid)\n",
    "ELASTIC07_valid = ELASTIC07.predict(X_valid)\n",
    "ELASTIC08_valid = ELASTIC08.predict(X_valid)\n",
    "ELASTIC09_valid = ELASTIC09.predict(X_valid)\n",
    "ELASTIC10_valid = ELASTIC10.predict(X_valid)\n",
    "\n",
    "BR001_valid = BR001.predict(X_valid)\n",
    "BR002_valid = BR002.predict(X_valid)\n",
    "BR003_valid = BR003.predict(X_valid)\n",
    "BR004_valid = BR004.predict(X_valid)\n",
    "BR005_valid = BR005.predict(X_valid)\n",
    "BR006_valid = BR006.predict(X_valid)\n",
    "BR007_valid = BR007.predict(X_valid)\n",
    "BR008_valid = BR008.predict(X_valid)\n",
    "BR009_valid = BR009.predict(X_valid)\n",
    "BR010_valid = BR010.predict(X_valid)\n",
    "\n",
    "LASSO_valid = LASSO.predict(X_valid)\n",
    "\n",
    "RIDGE01_valid = RIDGE01.predict(X_valid)\n",
    "RIDGE02_valid = RIDGE02.predict(X_valid)\n",
    "RIDGE03_valid = RIDGE03.predict(X_valid)\n",
    "RIDGE04_valid = RIDGE04.predict(X_valid)\n",
    "RIDGE05_valid = RIDGE05.predict(X_valid)\n",
    "RIDGE06_valid = RIDGE06.predict(X_valid)\n",
    "RIDGE07_valid = RIDGE07.predict(X_valid)\n",
    "RIDGE08_valid = RIDGE08.predict(X_valid)\n",
    "RIDGE09_valid = RIDGE09.predict(X_valid)\n",
    "RIDGE10_valid = RIDGE10.predict(X_valid)\n",
    "\n",
    "LARS_valid = LARS.predict(X_valid)\n",
    "\n",
    "OMP_valid = OMP.predict(X_valid)\n",
    "\n",
    "ARD01_valid = ARD01.predict(X_valid)\n",
    "ARD02_valid = ARD02.predict(X_valid)\n",
    "ARD03_valid = ARD03.predict(X_valid)\n",
    "ARD04_valid = ARD04.predict(X_valid)\n",
    "ARD05_valid = ARD05.predict(X_valid)\n",
    "ARD06_valid = ARD06.predict(X_valid)\n",
    "ARD07_valid = ARD07.predict(X_valid)\n",
    "ARD08_valid = ARD08.predict(X_valid)\n",
    "ARD09_valid = ARD09.predict(X_valid)\n",
    "ARD10_valid = ARD10.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_pickle('/opt/ml/level2-dkt-level2-recsys-08/data_pkl/test_data-1.pkl')\n",
    "\n",
    "test = test[test.answerCode==-1][FEATS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR01_test = LR01.predict_proba(test)\n",
    "LR02_test = LR02.predict_proba(test)\n",
    "LR03_test = LR03.predict_proba(test)\n",
    "LR04_test = LR04.predict_proba(test)\n",
    "LR05_test = LR05.predict_proba(test)\n",
    "LR06_test = LR06.predict_proba(test)\n",
    "LR07_test = LR07.predict_proba(test)\n",
    "LR08_test = LR08.predict_proba(test)\n",
    "LR09_test = LR09.predict_proba(test)\n",
    "LR10_test = LR10.predict_proba(test)\n",
    "\n",
    "ELASTIC01_test = ELASTIC01.predict(test)\n",
    "ELASTIC02_test = ELASTIC02.predict(test)\n",
    "ELASTIC03_test = ELASTIC03.predict(test)\n",
    "ELASTIC04_test = ELASTIC04.predict(test)\n",
    "ELASTIC05_test = ELASTIC05.predict(test)\n",
    "ELASTIC06_test = ELASTIC06.predict(test)\n",
    "ELASTIC07_test = ELASTIC07.predict(test)\n",
    "ELASTIC08_test = ELASTIC08.predict(test)\n",
    "ELASTIC09_test = ELASTIC09.predict(test)\n",
    "ELASTIC10_test = ELASTIC10.predict(test)\n",
    "\n",
    "BR001_test = BR001.predict(test)\n",
    "BR002_test = BR002.predict(test)\n",
    "BR003_test = BR003.predict(test)\n",
    "BR004_test = BR004.predict(test)\n",
    "BR005_test = BR005.predict(test)\n",
    "BR006_test = BR006.predict(test)\n",
    "BR007_test = BR007.predict(test)\n",
    "BR008_test = BR008.predict(test)\n",
    "BR009_test = BR009.predict(test)\n",
    "BR010_test = BR010.predict(test)\n",
    "\n",
    "LASSO_test = LASSO.predict(test)\n",
    "\n",
    "RIDGE01_test = RIDGE01.predict(test)\n",
    "RIDGE02_test = RIDGE02.predict(test)\n",
    "RIDGE03_test = RIDGE03.predict(test)\n",
    "RIDGE04_test = RIDGE04.predict(test)\n",
    "RIDGE05_test = RIDGE05.predict(test)\n",
    "RIDGE06_test = RIDGE06.predict(test)\n",
    "RIDGE07_test = RIDGE07.predict(test)\n",
    "RIDGE08_test = RIDGE08.predict(test)\n",
    "RIDGE09_test = RIDGE09.predict(test)\n",
    "RIDGE10_test = RIDGE10.predict(test)\n",
    "\n",
    "LARS_test = LARS.predict(test)\n",
    "\n",
    "OMP_test = OMP.predict(test)\n",
    "\n",
    "ARD01_test = ARD01.predict(test)\n",
    "ARD02_test = ARD02.predict(test)\n",
    "ARD03_test = ARD03.predict(test)\n",
    "ARD04_test = ARD04.predict(test)\n",
    "ARD05_test = ARD05.predict(test)\n",
    "ARD06_test = ARD06.predict(test)\n",
    "ARD07_test = ARD07.predict(test)\n",
    "ARD08_test = ARD08.predict(test)\n",
    "ARD09_test = ARD09.predict(test)\n",
    "ARD10_test = ARD10.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = '/opt/ml/level2-dkt-level2-recsys-08/LetsEnsemble/test4feature'\n",
    "valid_path = '/opt/ml/level2-dkt-level2-recsys-08/LetsEnsemble/valid4feature'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_to_csv(LR01_valid, os.path.join(valid_path, 'LR01_valid.csv'))\n",
    "test_to_csv(LR02_valid, os.path.join(valid_path, 'LR02_valid.csv'))\n",
    "test_to_csv(LR03_valid, os.path.join(valid_path, 'LR03_valid.csv'))\n",
    "test_to_csv(LR04_valid, os.path.join(valid_path, 'LR04_valid.csv'))\n",
    "test_to_csv(LR05_valid, os.path.join(valid_path, 'LR05_valid.csv'))\n",
    "test_to_csv(LR06_valid, os.path.join(valid_path, 'LR06_valid.csv'))\n",
    "test_to_csv(LR07_valid, os.path.join(valid_path, 'LR07_valid.csv'))\n",
    "test_to_csv(LR08_valid, os.path.join(valid_path, 'LR08_valid.csv'))\n",
    "test_to_csv(LR09_valid, os.path.join(valid_path, 'LR09_valid.csv'))\n",
    "test_to_csv(LR10_valid, os.path.join(valid_path, 'LR10_valid.csv'))\n",
    "\n",
    "test_to_csv(ELASTIC01_valid, os.path.join(valid_path, 'LR01_valid.csv'))\n",
    "test_to_csv(ELASTIC02_valid, os.path.join(valid_path, 'LR02_valid.csv'))\n",
    "test_to_csv(ELASTIC03_valid, os.path.join(valid_path, 'LR03_valid.csv'))\n",
    "test_to_csv(ELASTIC04_valid, os.path.join(valid_path, 'LR04_valid.csv'))\n",
    "test_to_csv(ELASTIC05_valid, os.path.join(valid_path, 'LR05_valid.csv'))\n",
    "test_to_csv(ELASTIC06_valid, os.path.join(valid_path, 'LR06_valid.csv'))\n",
    "test_to_csv(ELASTIC07_valid, os.path.join(valid_path, 'LR07_valid.csv'))\n",
    "test_to_csv(ELASTIC08_valid, os.path.join(valid_path, 'LR08_valid.csv'))\n",
    "test_to_csv(ELASTIC09_valid, os.path.join(valid_path, 'LR09_valid.csv'))\n",
    "test_to_csv(ELASTIC10_valid, os.path.join(valid_path, 'LR10_valid.csv'))\n",
    "\n",
    "test_to_csv(BR001_valid, os.path.join(valid_path, 'BR001_valid.csv'))\n",
    "test_to_csv(BR002_valid, os.path.join(valid_path, 'BR002_valid.csv'))\n",
    "test_to_csv(BR003_valid, os.path.join(valid_path, 'BR003_valid.csv'))\n",
    "test_to_csv(BR004_valid, os.path.join(valid_path, 'BR004_valid.csv'))\n",
    "test_to_csv(BR005_valid, os.path.join(valid_path, 'BR005_valid.csv'))\n",
    "test_to_csv(BR006_valid, os.path.join(valid_path, 'BR006_valid.csv'))\n",
    "test_to_csv(BR007_valid, os.path.join(valid_path, 'BR007_valid.csv'))\n",
    "test_to_csv(BR008_valid, os.path.join(valid_path, 'BR008_valid.csv'))\n",
    "test_to_csv(BR009_valid, os.path.join(valid_path, 'BR009_valid.csv'))\n",
    "test_to_csv(BR010_valid, os.path.join(valid_path, 'BR010_valid.csv'))\n",
    "\n",
    "\n",
    "test_to_csv(RIDGE01_valid, os.path.join(valid_path, 'RIDGE01_valid.csv'))\n",
    "test_to_csv(RIDGE02_valid, os.path.join(valid_path, 'RIDGE02_valid.csv'))\n",
    "test_to_csv(RIDGE03_valid, os.path.join(valid_path, 'RIDGE03_valid.csv'))\n",
    "test_to_csv(RIDGE04_valid, os.path.join(valid_path, 'RIDGE04_valid.csv'))\n",
    "test_to_csv(RIDGE05_valid, os.path.join(valid_path, 'RIDGE05_valid.csv'))\n",
    "test_to_csv(RIDGE06_valid, os.path.join(valid_path, 'RIDGE06_valid.csv'))\n",
    "test_to_csv(RIDGE07_valid, os.path.join(valid_path, 'RIDGE07_valid.csv'))\n",
    "test_to_csv(RIDGE08_valid, os.path.join(valid_path, 'RIDGE08_valid.csv'))\n",
    "test_to_csv(RIDGE09_valid, os.path.join(valid_path, 'RIDGE09_valid.csv'))\n",
    "test_to_csv(RIDGE10_valid, os.path.join(valid_path, 'RIDGE10_valid.csv'))\n",
    "\n",
    "test_to_csv(LASSO_valid, os.path.join(valid_path, 'LASSO_valid.csv'))\n",
    "test_to_csv(LARS_valid, os.path.join(valid_path, 'LARS_valid.csv'))\n",
    "test_to_csv(OMP_valid, os.path.join(valid_path, 'OMP_valid.csv'))\n",
    "\n",
    "test_to_csv(ARD01_valid, os.path.join(valid_path, 'ARD01_valid.csv'))\n",
    "test_to_csv(ARD02_valid, os.path.join(valid_path, 'ARD02_valid.csv'))\n",
    "test_to_csv(ARD03_valid, os.path.join(valid_path, 'ARD03_valid.csv'))\n",
    "test_to_csv(ARD04_valid, os.path.join(valid_path, 'ARD04_valid.csv'))\n",
    "test_to_csv(ARD05_valid, os.path.join(valid_path, 'ARD05_valid.csv'))\n",
    "test_to_csv(ARD06_valid, os.path.join(valid_path, 'ARD06_valid.csv'))\n",
    "test_to_csv(ARD07_valid, os.path.join(valid_path, 'ARD07_valid.csv'))\n",
    "test_to_csv(ARD08_valid, os.path.join(valid_path, 'ARD08_valid.csv'))\n",
    "test_to_csv(ARD09_valid, os.path.join(valid_path, 'ARD09_valid.csv'))\n",
    "test_to_csv(ARD10_valid, os.path.join(valid_path, 'ARD10_valid.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_to_csv(LR01_test, os.path.join(test_path, 'LR01_test.csv'))\n",
    "test_to_csv(LR02_test, os.path.join(test_path, 'LR02_test.csv'))\n",
    "test_to_csv(LR03_test, os.path.join(test_path, 'LR03_test.csv'))\n",
    "test_to_csv(LR04_test, os.path.join(test_path, 'LR04_test.csv'))\n",
    "test_to_csv(LR05_test, os.path.join(test_path, 'LR05_test.csv'))\n",
    "test_to_csv(LR06_test, os.path.join(test_path, 'LR06_test.csv'))\n",
    "test_to_csv(LR07_test, os.path.join(test_path, 'LR07_test.csv'))\n",
    "test_to_csv(LR08_test, os.path.join(test_path, 'LR08_test.csv'))\n",
    "test_to_csv(LR09_test, os.path.join(test_path, 'LR09_test.csv'))\n",
    "test_to_csv(LR10_test, os.path.join(test_path, 'LR10_test.csv'))\n",
    "\n",
    "test_to_csv(ELASTIC01_test, os.path.join(test_path, 'LR01_test.csv'))\n",
    "test_to_csv(ELASTIC02_test, os.path.join(test_path, 'LR02_test.csv'))\n",
    "test_to_csv(ELASTIC03_test, os.path.join(test_path, 'LR03_test.csv'))\n",
    "test_to_csv(ELASTIC04_test, os.path.join(test_path, 'LR04_test.csv'))\n",
    "test_to_csv(ELASTIC05_test, os.path.join(test_path, 'LR05_test.csv'))\n",
    "test_to_csv(ELASTIC06_test, os.path.join(test_path, 'LR06_test.csv'))\n",
    "test_to_csv(ELASTIC07_test, os.path.join(test_path, 'LR07_test.csv'))\n",
    "test_to_csv(ELASTIC08_test, os.path.join(test_path, 'LR08_test.csv'))\n",
    "test_to_csv(ELASTIC09_test, os.path.join(test_path, 'LR09_test.csv'))\n",
    "test_to_csv(ELASTIC10_test, os.path.join(test_path, 'LR10_test.csv'))\n",
    "\n",
    "test_to_csv(BR001_test, os.path.join(test_path, 'BR001_test.csv'))\n",
    "test_to_csv(BR002_test, os.path.join(test_path, 'BR002_test.csv'))\n",
    "test_to_csv(BR003_test, os.path.join(test_path, 'BR003_test.csv'))\n",
    "test_to_csv(BR004_test, os.path.join(test_path, 'BR004_test.csv'))\n",
    "test_to_csv(BR005_test, os.path.join(test_path, 'BR005_test.csv'))\n",
    "test_to_csv(BR006_test, os.path.join(test_path, 'BR006_test.csv'))\n",
    "test_to_csv(BR007_test, os.path.join(test_path, 'BR007_test.csv'))\n",
    "test_to_csv(BR008_test, os.path.join(test_path, 'BR008_test.csv'))\n",
    "test_to_csv(BR009_test, os.path.join(test_path, 'BR009_test.csv'))\n",
    "test_to_csv(BR010_test, os.path.join(test_path, 'BR010_test.csv'))\n",
    "\n",
    "\n",
    "test_to_csv(RIDGE01_test, os.path.join(test_path, 'RIDGE01_test.csv'))\n",
    "test_to_csv(RIDGE02_test, os.path.join(test_path, 'RIDGE02_test.csv'))\n",
    "test_to_csv(RIDGE03_test, os.path.join(test_path, 'RIDGE03_test.csv'))\n",
    "test_to_csv(RIDGE04_test, os.path.join(test_path, 'RIDGE04_test.csv'))\n",
    "test_to_csv(RIDGE05_test, os.path.join(test_path, 'RIDGE05_test.csv'))\n",
    "test_to_csv(RIDGE06_test, os.path.join(test_path, 'RIDGE06_test.csv'))\n",
    "test_to_csv(RIDGE07_test, os.path.join(test_path, 'RIDGE07_test.csv'))\n",
    "test_to_csv(RIDGE08_test, os.path.join(test_path, 'RIDGE08_test.csv'))\n",
    "test_to_csv(RIDGE09_test, os.path.join(test_path, 'RIDGE09_test.csv'))\n",
    "test_to_csv(RIDGE10_test, os.path.join(test_path, 'RIDGE10_test.csv'))\n",
    "\n",
    "test_to_csv(LASSO_test, os.path.join(test_path, 'LASSO_test.csv'))\n",
    "test_to_csv(LARS_test, os.path.join(test_path, 'LARS_test.csv'))\n",
    "test_to_csv(OMP_test, os.path.join(test_path, 'OMP_test.csv'))\n",
    "\n",
    "test_to_csv(ARD01_test, os.path.join(test_path, 'ARD01_test.csv'))\n",
    "test_to_csv(ARD02_test, os.path.join(test_path, 'ARD02_test.csv'))\n",
    "test_to_csv(ARD03_test, os.path.join(test_path, 'ARD03_test.csv'))\n",
    "test_to_csv(ARD04_test, os.path.join(test_path, 'ARD04_test.csv'))\n",
    "test_to_csv(ARD05_test, os.path.join(test_path, 'ARD05_test.csv'))\n",
    "test_to_csv(ARD06_test, os.path.join(test_path, 'ARD06_test.csv'))\n",
    "test_to_csv(ARD07_test, os.path.join(test_path, 'ARD07_test.csv'))\n",
    "test_to_csv(ARD08_test, os.path.join(test_path, 'ARD08_test.csv'))\n",
    "test_to_csv(ARD09_test, os.path.join(test_path, 'ARD09_test.csv'))\n",
    "test_to_csv(ARD10_test, os.path.join(test_path, 'ARD10_test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
