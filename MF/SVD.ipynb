{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import RocCurveDisplay, accuracy_score, roc_auc_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "\n",
    "\n",
    "def get_metric(targets, preds):\n",
    "    auc = roc_auc_score(targets, preds)\n",
    "    acc = accuracy_score(targets, np.where(preds >= 0.5, 1, 0))\n",
    "    precsion = precision_score(targets, np.where(preds >= 0.5, 1, 0))\n",
    "    recall = recall_score(targets, np.where(preds >= 0.5, 1, 0))\n",
    "    F1_score = f1_score(targets, np.where(preds >= 0.5, 1, 0))\n",
    "\n",
    "    print('auc :',auc)\n",
    "    print('acc :',acc)\n",
    "    print('precision :',precsion)\n",
    "    print('recall :',recall)\n",
    "\n",
    "def test_to_csv(preds, name:str):\n",
    "    \n",
    "    result = []\n",
    "    for n,i in enumerate(preds):\n",
    "        row = {}    \n",
    "        row['id'] = n\n",
    "        row['prediction'] = i\n",
    "        result.append(row)\n",
    "    pd.DataFrame(result).to_csv(f'output/{name}.csv', index=None)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cate_cols = [\n",
    "            # 'assessmentItemID',\n",
    "            # 'testId',\n",
    "            # 'KnowledgeTag',\n",
    "            'hour',\n",
    "            'dow',\n",
    "            'i_head',\n",
    "            'i_mid',\n",
    "            'i_tail',\n",
    "]\n",
    "cont_cols = [                        \n",
    "            'user_correct_answer',\n",
    "            'user_total_answer',\n",
    "            'user_acc',            \n",
    "            't_elapsed',            \n",
    "            'cum_correct',\n",
    "            'last_problem',\n",
    "            'head_term',\n",
    "            # 'left_asymptote',\n",
    "            'elo_prob',\n",
    "            'pkt',\n",
    "            'u_head_mean',\n",
    "            'u_head_count',\n",
    "            'u_head_std',\n",
    "            'u_head_elapsed',\n",
    "            'i_mid_elapsed',\n",
    "            'i_mid_mean',\n",
    "            'i_mid_std',\n",
    "            'i_mid_sum',\n",
    "            'i_mid_count',\n",
    "            'i_mid_tag_count',\n",
    "            # 'assessment_mean',\n",
    "            # 'assessment_sum',\n",
    "            # 'assessment_std',\n",
    "            'tag_mean',\n",
    "            'tag_sum',\n",
    "            # 'tag_std',\n",
    "            'tail_mean',\n",
    "            'tail_sum',\n",
    "            # 'tail_std',\n",
    "            'hour_mean',\n",
    "            'hour_sum',\n",
    "            # 'hour_std',\n",
    "            'dow_mean',\n",
    "            'dow_sum',\n",
    "            # 'dow_std',\n",
    "            'tag_elapsed',\n",
    "            'tag_elapsed_o',\n",
    "            'tag_elapsed_x',\n",
    "            'assessment_elapsed',\n",
    "            'assessment_elapsed_o',\n",
    "            'assessment_elapsed_x',\n",
    "            'tail_elapsed',\n",
    "            'tail_elapsed_o',\n",
    "            'tail_elapsed_x'\n",
    "            ]\n",
    "\n",
    "FEATS = cate_cols + cont_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('/opt/ml/level2-dkt-level2-recsys-08/data_pkl/all.pkl')\n",
    "label = data.answerCode.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_user = pd.read_csv('/opt/ml/input/data/cv_valid_data.csv').userID.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data[data.userID.isin(valid_user)==False]\n",
    "y_train = X_train.answerCode.to_numpy()\n",
    "X_valid = data[data.userID.isin(valid_user)==True]\n",
    "y_valid = X_valid.answerCode.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression(max_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=500)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR.fit(data[FEATS],label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_preds = LR.predict_proba(X_valid[FEATS])[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc : 0.728352180880359\n",
      "acc : 0.7176094513359342\n",
      "precision : 0.7333234794176335\n",
      "recall : 0.8942233170116255\n"
     ]
    }
   ],
   "source": [
    "get_metric(y_valid,valid_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_pickle('/opt/ml/level2-dkt-level2-recsys-08/data_pkl/test_data-1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test[test.answerCode==-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = LR.predict_proba(test[FEATS])[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_to_csv(test_preds,'LogisticR2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>assessmentItemID</th>\n",
       "      <th>elo_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1954</th>\n",
       "      <td>3</td>\n",
       "      <td>A050023001</td>\n",
       "      <td>0.617426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1955</th>\n",
       "      <td>3</td>\n",
       "      <td>A050023002</td>\n",
       "      <td>0.564765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956</th>\n",
       "      <td>3</td>\n",
       "      <td>A050023003</td>\n",
       "      <td>0.481622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1957</th>\n",
       "      <td>3</td>\n",
       "      <td>A050023004</td>\n",
       "      <td>0.672212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1958</th>\n",
       "      <td>3</td>\n",
       "      <td>A050023006</td>\n",
       "      <td>0.214407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2526671</th>\n",
       "      <td>7439</td>\n",
       "      <td>A040130001</td>\n",
       "      <td>0.280714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2526672</th>\n",
       "      <td>7439</td>\n",
       "      <td>A040130002</td>\n",
       "      <td>0.429547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2526673</th>\n",
       "      <td>7439</td>\n",
       "      <td>A040130003</td>\n",
       "      <td>0.805320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2526674</th>\n",
       "      <td>7439</td>\n",
       "      <td>A040130004</td>\n",
       "      <td>0.802161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2526675</th>\n",
       "      <td>7439</td>\n",
       "      <td>A040130005</td>\n",
       "      <td>0.531555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>260114 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         userID assessmentItemID  elo_prob\n",
       "1954          3       A050023001  0.617426\n",
       "1955          3       A050023002  0.564765\n",
       "1956          3       A050023003  0.481622\n",
       "1957          3       A050023004  0.672212\n",
       "1958          3       A050023006  0.214407\n",
       "...         ...              ...       ...\n",
       "2526671    7439       A040130001  0.280714\n",
       "2526672    7439       A040130002  0.429547\n",
       "2526673    7439       A040130003  0.805320\n",
       "2526674    7439       A040130004  0.802161\n",
       "2526675    7439       A040130005  0.531555\n",
       "\n",
       "[260114 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_pickle('/opt/ml/level2-dkt-level2-recsys-08/data_pkl/test_data-1.pkl')[['userID', 'assessmentItemID', 'elo_prob']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
